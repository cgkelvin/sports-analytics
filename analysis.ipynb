{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Deep-Dive on the Effects of Head Coaching Changes in the NBA\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The purpose of this project is to investigate the impact of head coach changes on underperforming NBA teams. In the NBA, head coaches are at the forefront of critique when a team underperforms. This usually results in a change of head coaching and, sometimes, the entire coaching staff; but, how effective is this strategy? This project aims to analyze the tangible effects of such coaching transitions on team performance in the subsequent seasons. My focus is on providing a data-driven exploration of the role head coaches play in the NBA and how these changes may influence the team's future performance.\n",
    "\n",
    "At the end of the 2022-2023 regular season, the Toronto Raptors placed 9th in the Eastern Conference Standings, marking their 2nd missed playoffs in the 3 seasons subsequent to their 2019 Championship run. This led the Raptors parting ways with head coach Nick Nurse as well with the majority of the coaching staff in the summer of 2023. This season, the Raptors hired Darko Rajakovic, an assistant coach from the Memphis Grizzlies to be their new head coach to implement new systems, offensive and defensive philosophies, and to facilitate development of the young Toronto Raptors core.\n",
    "\n",
    "Coming off high anticipation after the offseason, the Toronto Raptors are 2-4 to start the season. This raises the question: What level of impact can we relaistically expect from these coaching changes? This scenario provides a real-world backdrop for our comprehensive investigation intot he effects of coaching transitions across the NBA.\n",
    "\n",
    "We seek to answer several questions through exploratory data analysis (EDA):\n",
    "\n",
    "What is the average number of playoffs clinched within the first 3 years by teams that undergo head coaching changes? How does changing the head coach correlate with the average change in team win percentage in subsequent years? We will also delve into predictive modeling using neural networks (NN). The NN will help us predict the team's future win percentage and determine which seed they could potentially secure in their respective conference. Furthermore, we aim to predict the winningness of the team in subsequent years based on their regular-season records. These predictions will be categorized into:\n",
    "\n",
    "- High seed team (1-4)\n",
    "- Low seed team (5-8)\n",
    "- Out of playoff contention\n",
    "\n",
    "We can also measure a team's winningness by measuring playoff performance, predicting whether they will:\n",
    "\n",
    "- Win a championship\n",
    "- Clinch the conference finals\n",
    "- Clinch the playoffs\n",
    "\n",
    "Through this project, we aim to provide data-driven insights into the impact of coaching changes on NBA teams and their future performance, shedding light on the strategies employed in the dynamic world of professional basketball.\n",
    "\n",
    "## Data Sources\n",
    "\n",
    "This project uses [Swar's NBA API](https://github.com/swar/nba_api) for the acquisition of data accessible through https://stats.nba.com.\n",
    "\n",
    "## Collecting the Data\n",
    "\n",
    "In this section I'll be using the API to collect the data and construct the reporting table.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries and API endpoints\n",
    "\n",
    "import pandas as pd\n",
    "from nba_api.stats.endpoints import commonteamroster\n",
    "from nba_api.stats.static import teams\n",
    "from nba_api.stats.endpoints import playoffpicture\n",
    "from nba_api.stats.endpoints import teamdetails\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of team info\n",
    "team_info = teams.get_teams()\n",
    "head_coaches_data = []\n",
    "\n",
    "# Iterate through teams and seasons\n",
    "for team in team_info:\n",
    "    team_id = team['id']\n",
    "    team_name = team['abbreviation']\n",
    "    for season in range(2005, 2024):\n",
    "        coach_data = commonteamroster.CommonTeamRoster(team_id=team_id, season=season)\n",
    "        coach_data_df = coach_data.coaches.get_data_frame()\n",
    "        seasons = f\"{season}-{str(season+1)[-2:]}\"\n",
    "        if not coach_data_df.empty:\n",
    "            try:\n",
    "                coach_name = coach_data_df[coach_data_df['COACH_TYPE'] == 'Head Coach']['COACH_NAME'].values[0]\n",
    "            except IndexError:\n",
    "                coach_name = 'None'\n",
    "        head_coaches_data.append({\n",
    "            'Team ID': team_id,\n",
    "            'Season': seasons,\n",
    "            'Team': team_name,\n",
    "            'Coach': coach_name\n",
    "        })\n",
    "\n",
    "head_coaches_df = pd.DataFrame(head_coaches_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Team</th>\n",
       "      <th>Coach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1610612740</td>\n",
       "      <td>2014-15</td>\n",
       "      <td>NOP</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1610612743</td>\n",
       "      <td>2012-13</td>\n",
       "      <td>DEN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1610612747</td>\n",
       "      <td>2015-16</td>\n",
       "      <td>LAL</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>1610612755</td>\n",
       "      <td>2012-13</td>\n",
       "      <td>PHI</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>1610612756</td>\n",
       "      <td>2018-19</td>\n",
       "      <td>PHX</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1610612758</td>\n",
       "      <td>2015-16</td>\n",
       "      <td>SAC</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>1610612760</td>\n",
       "      <td>2014-15</td>\n",
       "      <td>OKC</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>CHA</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Team ID   Season Team Coach\n",
       "66   1610612740  2014-15  NOP  None\n",
       "121  1610612743  2012-13  DEN  None\n",
       "200  1610612747  2015-16  LAL  None\n",
       "349  1610612755  2012-13  PHI  None\n",
       "374  1610612756  2018-19  PHX  None\n",
       "409  1610612758  2015-16  SAC  None\n",
       "446  1610612760  2014-15  OKC  None\n",
       "567  1610612766  2021-22  CHA  None"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding no data instances - data isn't really clean \n",
    "no_data = head_coaches_df[head_coaches_df['Coach'] == 'None']\n",
    "no_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Team ID</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>Win PCT</th>\n",
       "      <th>Clinched Playoffs</th>\n",
       "      <th>Clinched Conference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-06</td>\n",
       "      <td>1</td>\n",
       "      <td>1610612765</td>\n",
       "      <td>64</td>\n",
       "      <td>18</td>\n",
       "      <td>0.780</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-06</td>\n",
       "      <td>2</td>\n",
       "      <td>1610612748</td>\n",
       "      <td>52</td>\n",
       "      <td>30</td>\n",
       "      <td>0.634</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-06</td>\n",
       "      <td>3</td>\n",
       "      <td>1610612739</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.610</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-06</td>\n",
       "      <td>4</td>\n",
       "      <td>1610612751</td>\n",
       "      <td>49</td>\n",
       "      <td>33</td>\n",
       "      <td>0.598</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-06</td>\n",
       "      <td>5</td>\n",
       "      <td>1610612764</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>0.512</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-24</td>\n",
       "      <td>11</td>\n",
       "      <td>1610612746</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-24</td>\n",
       "      <td>12</td>\n",
       "      <td>1610612762</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-24</td>\n",
       "      <td>13</td>\n",
       "      <td>1610612763</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-24</td>\n",
       "      <td>14</td>\n",
       "      <td>1610612757</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-24</td>\n",
       "      <td>15</td>\n",
       "      <td>1610612759</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>570 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Season Seed     Team ID Wins Losses  Win PCT Clinched Playoffs  \\\n",
       "0   2005-06    1  1610612765   64     18    0.780                 1   \n",
       "1   2005-06    2  1610612748   52     30    0.634                 1   \n",
       "2   2005-06    3  1610612739   50     32    0.610                 1   \n",
       "3   2005-06    4  1610612751   49     33    0.598                 1   \n",
       "4   2005-06    5  1610612764   42     40    0.512                 1   \n",
       "..      ...  ...         ...  ...    ...      ...               ...   \n",
       "10  2023-24   11  1610612746    4      7    0.364                 0   \n",
       "11  2023-24   12  1610612762    4      8    0.333                 0   \n",
       "12  2023-24   13  1610612763    3      9    0.250                 0   \n",
       "13  2023-24   14  1610612757    3      9    0.250                 0   \n",
       "14  2023-24   15  1610612759    3     10    0.231                 0   \n",
       "\n",
       "   Clinched Conference  \n",
       "0                    1  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "..                 ...  \n",
       "10                   0  \n",
       "11                   0  \n",
       "12                   0  \n",
       "13                   0  \n",
       "14                   0  \n",
       "\n",
       "[570 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playoff_picture_df = pd.DataFrame(columns=['Season', 'Seed', 'Team ID', 'Wins', 'Losses', 'Win PCT', 'Clinched Playoffs', 'Clinched Conference'])\n",
    "\n",
    "for season in range(2005, 2024):\n",
    "    playoff_picture = playoffpicture.PlayoffPicture(season_id='2' + str(season))\n",
    "\n",
    "    EastConfStandings_df = playoff_picture.east_conf_standings.get_data_frame()\n",
    "    EastConfPlayoffPicture_df = playoff_picture.east_conf_playoff_picture.get_data_frame()\n",
    "    east_team_wins = EastConfStandings_df['WINS']\n",
    "    east_team_losses = EastConfStandings_df['LOSSES']\n",
    "    east_team_seed = EastConfPlayoffPicture_df['HIGH_SEED_RANK'].combine_first(EastConfPlayoffPicture_df['LOW_SEED_RANK'])\n",
    "    east_team_pct = EastConfStandings_df['PCT']\n",
    "    #east_team = EastConfStandings_df['TEAM']\n",
    "    east_team_id = EastConfStandings_df['TEAM_ID']\n",
    "    east_team_clinched_playoffs = EastConfStandings_df['CLINCHED_PLAYOFFS']\n",
    "    east_team_clinched_conference = EastConfStandings_df['CLINCHED_CONFERENCE']\n",
    "\n",
    "    east_df = pd.DataFrame({\n",
    "        'Season': f\"{season}-{str(season+1)[-2:]}\",\n",
    "        'Team ID': east_team_id,\n",
    "        'Wins': east_team_wins,\n",
    "        'Losses': east_team_losses, \n",
    "        'Win PCT': east_team_pct,\n",
    "        'Clinched Playoffs': east_team_clinched_playoffs,\n",
    "        'Clinched Conference': east_team_clinched_conference\n",
    "        })\n",
    "    \n",
    "    WestConfStandings_df = playoff_picture.west_conf_standings.get_data_frame()\n",
    "    WestConfPlayoffPicture_df = playoff_picture.west_conf_playoff_picture.get_data_frame()\n",
    "    west_team_wins = WestConfStandings_df['WINS']\n",
    "    west_team_losses = WestConfStandings_df['LOSSES']\n",
    "    west_team_pct = WestConfStandings_df['PCT']\n",
    "    #west_team = WestConfStandings_df['TEAM']\n",
    "    west_team_id = WestConfStandings_df['TEAM_ID']\n",
    "    west_team_clinched_playoffs = WestConfStandings_df['CLINCHED_PLAYOFFS']\n",
    "    west_team_clinched_conference = WestConfStandings_df['CLINCHED_CONFERENCE']\n",
    "\n",
    "    west_df = pd.DataFrame({\n",
    "        'Season': f\"{season}-{str(season+1)[-2:]}\",\n",
    "        'Team ID': west_team_id,\n",
    "        'Wins': west_team_wins,\n",
    "        'Losses': west_team_losses, \n",
    "        'Win PCT': west_team_pct,\n",
    "        'Clinched Playoffs': west_team_clinched_playoffs,\n",
    "        'Clinched Conference': west_team_clinched_conference\n",
    "        })\n",
    "    east_df.reset_index(drop=True, inplace=True)\n",
    "    west_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    east_df['Seed'] = east_df.index + 1\n",
    "    west_df['Seed'] = west_df.index + 1\n",
    "\n",
    "    playoff_picture_df = pd.concat([playoff_picture_df, east_df, west_df])\n",
    "\n",
    "playoff_picture_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Won Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1610612738</td>\n",
       "      <td>2007-08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1610612739</td>\n",
       "      <td>2015-16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1610612742</td>\n",
       "      <td>2010-11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1610612743</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1610612744</td>\n",
       "      <td>2014-15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>2018-19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>2020-21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>570 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Team ID   Season  Won Title\n",
       "0    1610612738  2007-08          1\n",
       "1    1610612739  2015-16          1\n",
       "2    1610612742  2010-11          1\n",
       "3    1610612743  2022-23          1\n",
       "4    1610612744  2014-15          1\n",
       "..          ...      ...        ...\n",
       "565  1610612766  2018-19          0\n",
       "566  1610612766  2019-20          0\n",
       "567  1610612766  2020-21          0\n",
       "568  1610612766  2021-22          0\n",
       "569  1610612766  2022-23          0\n",
       "\n",
       "[570 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "teams = teams.get_teams()\n",
    "team_id = [team['id'] for team in teams]\n",
    "all_seasons = [f\"{year - 1}-{str(year)[-2:]}\" for year in range(2005, 2024)]\n",
    "\n",
    "for id in team_id:\n",
    "    champ = teamdetails.TeamDetails(team_id=id)\n",
    "    champ_df = champ.team_awards_championships.get_data_frame()\n",
    "    \n",
    "    if 'YEARAWARDED' in champ_df:\n",
    "        won_titles = champ_df[champ_df['YEARAWARDED'] >= 2005]\n",
    "        if not won_titles.empty:\n",
    "            seasons = won_titles['YEARAWARDED'].apply(lambda year: f\"{year - 1}-{str(year)[-2:]}\")\n",
    "            data.extend([(id, season, 1) for season in seasons])\n",
    "\n",
    "# Fill in missing entries with 0\n",
    "for id in team_id:\n",
    "    for season in all_seasons:\n",
    "        if not any((entry[0] == id and entry[1] == season) for entry in data):\n",
    "            data.append((id, season, 0))\n",
    "\n",
    "title_df = pd.DataFrame(data, columns=['Team ID', 'Season', 'Won Title'])\n",
    "title_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Team</th>\n",
       "      <th>Coach</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>Win PCT</th>\n",
       "      <th>Clinched Playoffs</th>\n",
       "      <th>Clinched Conference</th>\n",
       "      <th>Won Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2005-06</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Mike Woodson</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>56</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>1610612760</td>\n",
       "      <td>2005-06</td>\n",
       "      <td>OKC</td>\n",
       "      <td>Bob Hill</td>\n",
       "      <td>11</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1610612739</td>\n",
       "      <td>2005-06</td>\n",
       "      <td>CLE</td>\n",
       "      <td>Mike Brown</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.610</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>1610612759</td>\n",
       "      <td>2005-06</td>\n",
       "      <td>SAS</td>\n",
       "      <td>Gregg Popovich</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>19</td>\n",
       "      <td>0.768</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1610612758</td>\n",
       "      <td>2005-06</td>\n",
       "      <td>SAC</td>\n",
       "      <td>Rick Adelman</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>38</td>\n",
       "      <td>0.537</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>1610612760</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>OKC</td>\n",
       "      <td>Mark Daigneault</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>1610612761</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>TOR</td>\n",
       "      <td>Darko Rajakovic</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>1610612762</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>UTA</td>\n",
       "      <td>Will Hardy</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Wes Unseld Jr</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>CHA</td>\n",
       "      <td>Steve Clifford</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>570 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Team ID   Season Team            Coach Seed Wins Losses  Win PCT  \\\n",
       "0    1610612737  2005-06  ATL     Mike Woodson   14   26     56    0.317   \n",
       "437  1610612760  2005-06  OKC         Bob Hill   11   35     47    0.427   \n",
       "38   1610612739  2005-06  CLE       Mike Brown    3   50     32    0.610   \n",
       "418  1610612759  2005-06  SAS   Gregg Popovich    1   63     19    0.768   \n",
       "399  1610612758  2005-06  SAC     Rick Adelman    8   44     38    0.537   \n",
       "..          ...      ...  ...              ...  ...  ...    ...      ...   \n",
       "455  1610612760  2023-24  OKC  Mark Daigneault    4    9      4    0.692   \n",
       "474  1610612761  2023-24  TOR  Darko Rajakovic   11    5      7    0.417   \n",
       "493  1610612762  2023-24  UTA       Will Hardy   12    4      8    0.333   \n",
       "531  1610612764  2023-24  WAS    Wes Unseld Jr   14    2     10    0.167   \n",
       "569  1610612766  2023-24  CHA   Steve Clifford   13    3      9    0.250   \n",
       "\n",
       "    Clinched Playoffs Clinched Conference  Won Title  \n",
       "0                   0                   0        0.0  \n",
       "437                 0                   0        0.0  \n",
       "38                  1                   0        0.0  \n",
       "418                 1                   1        0.0  \n",
       "399                 1                   0        0.0  \n",
       "..                ...                 ...        ...  \n",
       "455                 0                   0        NaN  \n",
       "474                 0                   0        NaN  \n",
       "493                 0                   0        NaN  \n",
       "531                 0                   0        NaN  \n",
       "569                 0                   0        NaN  \n",
       "\n",
       "[570 rows x 11 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.merge(head_coaches_df, playoff_picture_df, on=['Team ID', 'Season'], how='left')\n",
    "combined_df = pd.merge(combined_df, title_df, how='left')\n",
    "combined_df = combined_df.sort_values(by='Season')\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "**v1 (Current)**\n",
    "- Coach experience (YoE)\n",
    "- Coach track record (W/L)\n",
    "- Historical team performance (T-3 seasons average)\n",
    "\n",
    "v2\n",
    "- Player stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a seed type for classification\n",
    "\n",
    "seed_data = []\n",
    "\n",
    "for seed in combined_df.Seed:\n",
    "    if seed < 5: \n",
    "        seed_data.append(1) # seeds 1-4\n",
    "    elif seed < 9: \n",
    "        seed_data.append(2) # seeds 5-8\n",
    "    else:\n",
    "        seed_data.append(3) # below 8th seed\n",
    "\n",
    "seed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Team</th>\n",
       "      <th>Coach</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Seed Type</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>Win PCT</th>\n",
       "      <th>Clinched Playoffs</th>\n",
       "      <th>Clinched Conference</th>\n",
       "      <th>Won Title</th>\n",
       "      <th>Agg. Coach Wins</th>\n",
       "      <th>Agg. Coach Losses</th>\n",
       "      <th>Coach Experience</th>\n",
       "      <th>Agg. Playoffs Coached</th>\n",
       "      <th>Agg. Conference Finals Coached</th>\n",
       "      <th>Agg. Coach Titles Won</th>\n",
       "      <th>New Coach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2005-06</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Mike Woodson</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>56</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2006-07</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Mike Woodson</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>52</td>\n",
       "      <td>0.366</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56</td>\n",
       "      <td>108</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2007-08</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Mike Woodson</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "      <td>0.451</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93</td>\n",
       "      <td>153</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2008-09</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Mike Woodson</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>35</td>\n",
       "      <td>0.573</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140</td>\n",
       "      <td>188</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2009-10</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Mike Woodson</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>29</td>\n",
       "      <td>0.646</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>193</td>\n",
       "      <td>217</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Scott Brooks</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>47</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>488</td>\n",
       "      <td>388</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2020-21</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Scott Brooks</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td>0.472</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>522</td>\n",
       "      <td>426</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Wes Unseld Jr</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Wes Unseld Jr</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Wes Unseld Jr</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>570 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Team ID   Season Team          Coach Seed  Seed Type Wins Losses  \\\n",
       "0    1610612737  2005-06  ATL   Mike Woodson   14          3   26     56   \n",
       "1    1610612737  2006-07  ATL   Mike Woodson   13          3   30     52   \n",
       "2    1610612737  2007-08  ATL   Mike Woodson    8          2   37     45   \n",
       "3    1610612737  2008-09  ATL   Mike Woodson    4          1   47     35   \n",
       "4    1610612737  2009-10  ATL   Mike Woodson    3          1   53     29   \n",
       "..          ...      ...  ...            ...  ...        ...  ...    ...   \n",
       "565  1610612764  2019-20  WAS   Scott Brooks    9          3   25     47   \n",
       "566  1610612764  2020-21  WAS   Scott Brooks    8          2   34     38   \n",
       "567  1610612764  2021-22  WAS  Wes Unseld Jr   12          3   35     47   \n",
       "568  1610612764  2022-23  WAS  Wes Unseld Jr   12          3   35     47   \n",
       "569  1610612764  2023-24  WAS  Wes Unseld Jr   14          3    2     10   \n",
       "\n",
       "     Win PCT Clinched Playoffs Clinched Conference  Won Title  \\\n",
       "0      0.317                 0                   0        0.0   \n",
       "1      0.366                 1                   0        0.0   \n",
       "2      0.451                 1                   0        0.0   \n",
       "3      0.573                 1                   0        0.0   \n",
       "4      0.646                 1                   0        0.0   \n",
       "..       ...               ...                 ...        ...   \n",
       "565    0.347                 0                   0        0.0   \n",
       "566    0.472                 1                   0        0.0   \n",
       "567    0.427                 0                   0        0.0   \n",
       "568    0.427                 0                   0        0.0   \n",
       "569    0.167                 0                   0        NaN   \n",
       "\n",
       "     Agg. Coach Wins  Agg. Coach Losses  Coach Experience  \\\n",
       "0                 26                 56                 1   \n",
       "1                 56                108                 2   \n",
       "2                 93                153                 3   \n",
       "3                140                188                 4   \n",
       "4                193                217                 5   \n",
       "..               ...                ...               ...   \n",
       "565              488                388                11   \n",
       "566              522                426                12   \n",
       "567               35                 47                 1   \n",
       "568               70                 94                 2   \n",
       "569               72                104                 3   \n",
       "\n",
       "     Agg. Playoffs Coached  Agg. Conference Finals Coached  \\\n",
       "0                        0                               0   \n",
       "1                        1                               0   \n",
       "2                        2                               0   \n",
       "3                        3                               0   \n",
       "4                        4                               0   \n",
       "..                     ...                             ...   \n",
       "565                      7                               1   \n",
       "566                      8                               1   \n",
       "567                      0                               0   \n",
       "568                      0                               0   \n",
       "569                      0                               0   \n",
       "\n",
       "     Agg. Coach Titles Won  New Coach  \n",
       "0                      0.0       True  \n",
       "1                      0.0      False  \n",
       "2                      0.0      False  \n",
       "3                      0.0      False  \n",
       "4                      0.0      False  \n",
       "..                     ...        ...  \n",
       "565                    0.0      False  \n",
       "566                    0.0      False  \n",
       "567                    0.0       True  \n",
       "568                    0.0      False  \n",
       "569                    0.0      False  \n",
       "\n",
       "[570 rows x 19 columns]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combined_df.drop(columns='Seed Type')\n",
    "#combined_df.insert(5, 'Seed Type', seed_data)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Team</th>\n",
       "      <th>Coach</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Seed Type</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>Win PCT</th>\n",
       "      <th>Clinched Playoffs</th>\n",
       "      <th>...</th>\n",
       "      <th>Agg. Coach Wins</th>\n",
       "      <th>Agg. Coach Losses</th>\n",
       "      <th>Coach Experience</th>\n",
       "      <th>Agg. Playoffs Coached</th>\n",
       "      <th>Agg. Conference Finals Coached</th>\n",
       "      <th>Agg. Coach Titles Won</th>\n",
       "      <th>New Coach</th>\n",
       "      <th>Avg Wins T-5 Seasons</th>\n",
       "      <th>Avg Losses T-5 Seasons</th>\n",
       "      <th>Avg Win PCT T-5 Seasons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2005-06</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Mike Woodson</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>56</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2006-07</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Mike Woodson</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>52</td>\n",
       "      <td>0.366</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>108</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2007-08</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Mike Woodson</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "      <td>0.451</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>93</td>\n",
       "      <td>153</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2008-09</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Mike Woodson</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>35</td>\n",
       "      <td>0.573</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>140</td>\n",
       "      <td>188</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2009-10</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Mike Woodson</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>29</td>\n",
       "      <td>0.646</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>193</td>\n",
       "      <td>217</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>38.6</td>\n",
       "      <td>43.4</td>\n",
       "      <td>0.4706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Scott Brooks</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>47</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>488</td>\n",
       "      <td>388</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>38.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.4718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2020-21</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Scott Brooks</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td>0.472</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>522</td>\n",
       "      <td>426</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>36.6</td>\n",
       "      <td>41.4</td>\n",
       "      <td>0.4662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Wes Unseld Jr</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>33.8</td>\n",
       "      <td>44.2</td>\n",
       "      <td>0.4320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Wes Unseld Jr</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>32.2</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.4126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Wes Unseld Jr</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>72</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>26.2</td>\n",
       "      <td>37.8</td>\n",
       "      <td>0.3680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>570 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Team ID   Season Team          Coach Seed  Seed Type  Wins  Losses  \\\n",
       "0    1610612737  2005-06  ATL   Mike Woodson   14          3    26      56   \n",
       "1    1610612737  2006-07  ATL   Mike Woodson   13          3    30      52   \n",
       "2    1610612737  2007-08  ATL   Mike Woodson    8          2    37      45   \n",
       "3    1610612737  2008-09  ATL   Mike Woodson    4          1    47      35   \n",
       "4    1610612737  2009-10  ATL   Mike Woodson    3          1    53      29   \n",
       "..          ...      ...  ...            ...  ...        ...   ...     ...   \n",
       "565  1610612764  2019-20  WAS   Scott Brooks    9          3    25      47   \n",
       "566  1610612764  2020-21  WAS   Scott Brooks    8          2    34      38   \n",
       "567  1610612764  2021-22  WAS  Wes Unseld Jr   12          3    35      47   \n",
       "568  1610612764  2022-23  WAS  Wes Unseld Jr   12          3    35      47   \n",
       "569  1610612764  2023-24  WAS  Wes Unseld Jr   14          3     2      10   \n",
       "\n",
       "     Win PCT Clinched Playoffs  ... Agg. Coach Wins  Agg. Coach Losses  \\\n",
       "0      0.317                 0  ...              26                 56   \n",
       "1      0.366                 1  ...              56                108   \n",
       "2      0.451                 1  ...              93                153   \n",
       "3      0.573                 1  ...             140                188   \n",
       "4      0.646                 1  ...             193                217   \n",
       "..       ...               ...  ...             ...                ...   \n",
       "565    0.347                 0  ...             488                388   \n",
       "566    0.472                 1  ...             522                426   \n",
       "567    0.427                 0  ...              35                 47   \n",
       "568    0.427                 0  ...              70                 94   \n",
       "569    0.167                 0  ...              72                104   \n",
       "\n",
       "     Coach Experience  Agg. Playoffs Coached  Agg. Conference Finals Coached  \\\n",
       "0                   1                      0                               0   \n",
       "1                   2                      1                               0   \n",
       "2                   3                      2                               0   \n",
       "3                   4                      3                               0   \n",
       "4                   5                      4                               0   \n",
       "..                ...                    ...                             ...   \n",
       "565                11                      7                               1   \n",
       "566                12                      8                               1   \n",
       "567                 1                      0                               0   \n",
       "568                 2                      0                               0   \n",
       "569                 3                      0                               0   \n",
       "\n",
       "     Agg. Coach Titles Won  New Coach  Avg Wins T-5 Seasons  \\\n",
       "0                      0.0       True                   NaN   \n",
       "1                      0.0      False                   NaN   \n",
       "2                      0.0      False                   NaN   \n",
       "3                      0.0      False                   NaN   \n",
       "4                      0.0      False                  38.6   \n",
       "..                     ...        ...                   ...   \n",
       "565                    0.0      False                  38.0   \n",
       "566                    0.0      False                  36.6   \n",
       "567                    0.0       True                  33.8   \n",
       "568                    0.0      False                  32.2   \n",
       "569                    0.0      False                  26.2   \n",
       "\n",
       "     Avg Losses T-5 Seasons  Avg Win PCT T-5 Seasons  \n",
       "0                       NaN                      NaN  \n",
       "1                       NaN                      NaN  \n",
       "2                       NaN                      NaN  \n",
       "3                       NaN                      NaN  \n",
       "4                      43.4                   0.4706  \n",
       "..                      ...                      ...  \n",
       "565                    42.0                   0.4718  \n",
       "566                    41.4                   0.4662  \n",
       "567                    44.2                   0.4320  \n",
       "568                    45.8                   0.4126  \n",
       "569                    37.8                   0.3680  \n",
       "\n",
       "[570 rows x 22 columns]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_prev_seasons = 5\n",
    "\n",
    "combined_df_sortavg = combined_df.sort_values(by = ['Season', 'Team'])\n",
    "combined_df['Avg Wins T-5 Seasons'] = combined_df_sortavg.groupby('Team')['Wins'].rolling(window=num_prev_seasons).mean().reset_index(0, drop=True)\n",
    "combined_df['Avg Losses T-5 Seasons'] = combined_df_sortavg.groupby('Team')['Losses'].rolling(window=num_prev_seasons).mean().reset_index(0, drop=True)\n",
    "combined_df['Avg Win PCT T-5 Seasons'] = combined_df_sortavg.groupby('Team')['Win PCT'].rolling(window=num_prev_seasons).mean().reset_index(0, drop=True)\n",
    "\n",
    "combined_df['Wins'] = pd.to_numeric(combined_df['Wins'], errors='coerce')\n",
    "combined_df['Losses'] = pd.to_numeric(combined_df['Losses'], errors='coerce')\n",
    "\n",
    "for index, won_title in combined_df['Won Title'].items():\n",
    "    if pd.isna(won_title):\n",
    "        combined_df.at[index, 'Won Title'] = 0\n",
    "\n",
    "combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.getcwd()\n",
    "#combined_df.to_csv('/Users/kelvin/Documents/projects-learning/repositories/sports-analytics/coaches.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "coaches_fixed_df = pd.read_csv('/Users/kelvin/Documents/projects-learning/repositories/sports-analytics/coaches.csv')\n",
    "coaches_df = coaches_fixed_df['Coach']\n",
    "\n",
    "coaches_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Team</th>\n",
       "      <th>Coach</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>Win PCT</th>\n",
       "      <th>Clinched Playoffs</th>\n",
       "      <th>Clinched Conference</th>\n",
       "      <th>Won Title</th>\n",
       "      <th>Avg Wins T-5 Seasons</th>\n",
       "      <th>Avg Losses T-5 Seasons</th>\n",
       "      <th>Avg Win PCT T-5 Seasons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2005-06</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Mike Woodson</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>56</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2006-07</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Mike Woodson</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>52</td>\n",
       "      <td>0.366</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2007-08</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Mike Woodson</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "      <td>0.451</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2008-09</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Mike Woodson</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>35</td>\n",
       "      <td>0.573</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2009-10</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Mike Woodson</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>29</td>\n",
       "      <td>0.646</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.6</td>\n",
       "      <td>43.4</td>\n",
       "      <td>0.4706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Scott Brooks</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>47</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.4718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2020-21</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Scott Brooks</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td>0.472</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.6</td>\n",
       "      <td>41.4</td>\n",
       "      <td>0.4662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Wes Unseld Jr</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.8</td>\n",
       "      <td>44.2</td>\n",
       "      <td>0.4320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Wes Unseld Jr</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.2</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.4126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Wes Unseld Jr</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>37.8</td>\n",
       "      <td>0.3680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>570 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Team ID   Season Team          Coach Seed  Wins  Losses  Win PCT  \\\n",
       "0    1610612737  2005-06  ATL   Mike Woodson   14    26      56    0.317   \n",
       "1    1610612737  2006-07  ATL   Mike Woodson   13    30      52    0.366   \n",
       "2    1610612737  2007-08  ATL   Mike Woodson    8    37      45    0.451   \n",
       "3    1610612737  2008-09  ATL   Mike Woodson    4    47      35    0.573   \n",
       "4    1610612737  2009-10  ATL   Mike Woodson    3    53      29    0.646   \n",
       "..          ...      ...  ...            ...  ...   ...     ...      ...   \n",
       "565  1610612764  2019-20  WAS   Scott Brooks    9    25      47    0.347   \n",
       "566  1610612764  2020-21  WAS   Scott Brooks    8    34      38    0.472   \n",
       "567  1610612764  2021-22  WAS  Wes Unseld Jr   12    35      47    0.427   \n",
       "568  1610612764  2022-23  WAS  Wes Unseld Jr   12    35      47    0.427   \n",
       "569  1610612764  2023-24  WAS  Wes Unseld Jr   14     2      10    0.167   \n",
       "\n",
       "    Clinched Playoffs Clinched Conference  Won Title  Avg Wins T-5 Seasons  \\\n",
       "0                   0                   0        0.0                   NaN   \n",
       "1                   1                   0        0.0                   NaN   \n",
       "2                   1                   0        0.0                   NaN   \n",
       "3                   1                   0        0.0                   NaN   \n",
       "4                   1                   0        0.0                  38.6   \n",
       "..                ...                 ...        ...                   ...   \n",
       "565                 0                   0        0.0                  38.0   \n",
       "566                 1                   0        0.0                  36.6   \n",
       "567                 0                   0        0.0                  33.8   \n",
       "568                 0                   0        0.0                  32.2   \n",
       "569                 0                   0        0.0                  26.2   \n",
       "\n",
       "     Avg Losses T-5 Seasons  Avg Win PCT T-5 Seasons  \n",
       "0                       NaN                      NaN  \n",
       "1                       NaN                      NaN  \n",
       "2                       NaN                      NaN  \n",
       "3                       NaN                      NaN  \n",
       "4                      43.4                   0.4706  \n",
       "..                      ...                      ...  \n",
       "565                    42.0                   0.4718  \n",
       "566                    41.4                   0.4662  \n",
       "567                    44.2                   0.4320  \n",
       "568                    45.8                   0.4126  \n",
       "569                    37.8                   0.3680  \n",
       "\n",
       "[570 rows x 14 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combined_df_coachagg.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#combined_df = combined_df.drop(columns='Coach')\n",
    "#combined_df_coachagg = combined_df.sort_values(by = ['Team', 'Season'])\n",
    "#combined_df_coachagg = combined_df_coachagg.drop(columns='Coach')\n",
    "#combined_df_coachagg = combined_df_coachagg.sort_values(['Team', 'Season'])\n",
    "combined_df_coachagg.insert(loc=3, column='Coach', value=coaches_df)\n",
    "#combined_df_coachagg.reset_index(drop=True, inplace=True)\n",
    "combined_df_coachagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Team</th>\n",
       "      <th>Coach</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>Win PCT</th>\n",
       "      <th>Clinched Playoffs</th>\n",
       "      <th>Clinched Conference</th>\n",
       "      <th>...</th>\n",
       "      <th>Avg Wins T-5 Seasons</th>\n",
       "      <th>Avg Losses T-5 Seasons</th>\n",
       "      <th>Avg Win PCT T-5 Seasons</th>\n",
       "      <th>Agg. Coach Wins</th>\n",
       "      <th>Agg. Coach Losses</th>\n",
       "      <th>Helper</th>\n",
       "      <th>Coach Experience</th>\n",
       "      <th>Agg. Playoffs Coached</th>\n",
       "      <th>Agg. Conference Finals Coached</th>\n",
       "      <th>Agg. Coach Titles Won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2005-06</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Mike Woodson</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>56</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2006-07</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Mike Woodson</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>52</td>\n",
       "      <td>0.366</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2007-08</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Mike Woodson</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "      <td>0.451</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2008-09</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Mike Woodson</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>35</td>\n",
       "      <td>0.573</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>188</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2009-10</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Mike Woodson</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>29</td>\n",
       "      <td>0.646</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.6</td>\n",
       "      <td>43.4</td>\n",
       "      <td>0.4706</td>\n",
       "      <td>193</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Scott Brooks</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>47</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.4718</td>\n",
       "      <td>488</td>\n",
       "      <td>388</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2020-21</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Scott Brooks</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td>0.472</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36.6</td>\n",
       "      <td>41.4</td>\n",
       "      <td>0.4662</td>\n",
       "      <td>522</td>\n",
       "      <td>426</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Wes Unseld Jr</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.8</td>\n",
       "      <td>44.2</td>\n",
       "      <td>0.4320</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Wes Unseld Jr</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.2</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.4126</td>\n",
       "      <td>70</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Wes Unseld Jr</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.2</td>\n",
       "      <td>37.8</td>\n",
       "      <td>0.3680</td>\n",
       "      <td>72</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>570 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Team ID   Season Team          Coach Seed  Wins  Losses  Win PCT  \\\n",
       "0    1610612737  2005-06  ATL   Mike Woodson   14    26      56    0.317   \n",
       "1    1610612737  2006-07  ATL   Mike Woodson   13    30      52    0.366   \n",
       "2    1610612737  2007-08  ATL   Mike Woodson    8    37      45    0.451   \n",
       "3    1610612737  2008-09  ATL   Mike Woodson    4    47      35    0.573   \n",
       "4    1610612737  2009-10  ATL   Mike Woodson    3    53      29    0.646   \n",
       "..          ...      ...  ...            ...  ...   ...     ...      ...   \n",
       "565  1610612764  2019-20  WAS   Scott Brooks    9    25      47    0.347   \n",
       "566  1610612764  2020-21  WAS   Scott Brooks    8    34      38    0.472   \n",
       "567  1610612764  2021-22  WAS  Wes Unseld Jr   12    35      47    0.427   \n",
       "568  1610612764  2022-23  WAS  Wes Unseld Jr   12    35      47    0.427   \n",
       "569  1610612764  2023-24  WAS  Wes Unseld Jr   14     2      10    0.167   \n",
       "\n",
       "     Clinched Playoffs  Clinched Conference  ...  Avg Wins T-5 Seasons  \\\n",
       "0                    0                    0  ...                   NaN   \n",
       "1                    1                    0  ...                   NaN   \n",
       "2                    1                    0  ...                   NaN   \n",
       "3                    1                    0  ...                   NaN   \n",
       "4                    1                    0  ...                  38.6   \n",
       "..                 ...                  ...  ...                   ...   \n",
       "565                  0                    0  ...                  38.0   \n",
       "566                  1                    0  ...                  36.6   \n",
       "567                  0                    0  ...                  33.8   \n",
       "568                  0                    0  ...                  32.2   \n",
       "569                  0                    0  ...                  26.2   \n",
       "\n",
       "     Avg Losses T-5 Seasons  Avg Win PCT T-5 Seasons  Agg. Coach Wins  \\\n",
       "0                       NaN                      NaN               26   \n",
       "1                       NaN                      NaN               56   \n",
       "2                       NaN                      NaN               93   \n",
       "3                       NaN                      NaN              140   \n",
       "4                      43.4                   0.4706              193   \n",
       "..                      ...                      ...              ...   \n",
       "565                    42.0                   0.4718              488   \n",
       "566                    41.4                   0.4662              522   \n",
       "567                    44.2                   0.4320               35   \n",
       "568                    45.8                   0.4126               70   \n",
       "569                    37.8                   0.3680               72   \n",
       "\n",
       "     Agg. Coach Losses  Helper  Coach Experience  Agg. Playoffs Coached  \\\n",
       "0                   56       1                 1                      0   \n",
       "1                  108       1                 2                      1   \n",
       "2                  153       1                 3                      2   \n",
       "3                  188       1                 4                      3   \n",
       "4                  217       1                 5                      4   \n",
       "..                 ...     ...               ...                    ...   \n",
       "565                388       1                11                      7   \n",
       "566                426       1                12                      8   \n",
       "567                 47       1                 1                      0   \n",
       "568                 94       1                 2                      0   \n",
       "569                104       1                 3                      0   \n",
       "\n",
       "     Agg. Conference Finals Coached  Agg. Coach Titles Won  \n",
       "0                                 0                    0.0  \n",
       "1                                 0                    0.0  \n",
       "2                                 0                    0.0  \n",
       "3                                 0                    0.0  \n",
       "4                                 0                    0.0  \n",
       "..                              ...                    ...  \n",
       "565                               1                    0.0  \n",
       "566                               1                    0.0  \n",
       "567                               0                    0.0  \n",
       "568                               0                    0.0  \n",
       "569                               0                    0.0  \n",
       "\n",
       "[570 rows x 21 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_numeric = ['Clinched Playoffs', 'Clinched Conference', 'Won Title']\n",
    "combined_df_coachagg[columns_to_numeric] = combined_df_coachagg[columns_to_numeric].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "combined_df_coachagg['Agg. Coach Wins'] = combined_df_coachagg.groupby('Coach')['Wins'].cumsum()\n",
    "combined_df_coachagg['Agg. Coach Losses'] = combined_df_coachagg.groupby('Coach')['Losses'].cumsum()\n",
    "combined_df_coachagg['Helper'] = 1\n",
    "combined_df_coachagg['Coach Experience'] = combined_df_coachagg.groupby('Coach')['Helper'].cumsum()\n",
    "combined_df_coachagg['Agg. Playoffs Coached'] = combined_df_coachagg.groupby('Coach')['Clinched Playoffs'].cumsum()\n",
    "combined_df_coachagg['Agg. Conference Finals Coached'] = combined_df_coachagg.groupby('Coach')['Clinched Conference'].cumsum()\n",
    "combined_df_coachagg['Agg. Coach Titles Won'] = combined_df_coachagg.groupby('Coach')['Won Title'].cumsum()\n",
    "\n",
    "combined_df_coachagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Team</th>\n",
       "      <th>Coach</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>Win PCT</th>\n",
       "      <th>Clinched Playoffs</th>\n",
       "      <th>Clinched Conference</th>\n",
       "      <th>...</th>\n",
       "      <th>Avg Losses T-5 Seasons</th>\n",
       "      <th>Avg Win PCT T-5 Seasons</th>\n",
       "      <th>Agg. Coach Wins</th>\n",
       "      <th>Agg. Coach Losses</th>\n",
       "      <th>Helper</th>\n",
       "      <th>Coach Experience</th>\n",
       "      <th>Agg. Playoffs Coached</th>\n",
       "      <th>Agg. Conference Finals Coached</th>\n",
       "      <th>Agg. Coach Titles Won</th>\n",
       "      <th>New Coach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2005-06</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Mike Woodson</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>56</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2006-07</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Mike Woodson</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>52</td>\n",
       "      <td>0.366</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2007-08</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Mike Woodson</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "      <td>0.451</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2008-09</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Mike Woodson</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>35</td>\n",
       "      <td>0.573</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140</td>\n",
       "      <td>188</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2009-10</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Mike Woodson</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>29</td>\n",
       "      <td>0.646</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.4</td>\n",
       "      <td>0.4706</td>\n",
       "      <td>193</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Scott Brooks</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>47</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.4718</td>\n",
       "      <td>488</td>\n",
       "      <td>388</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2020-21</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Scott Brooks</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td>0.472</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.4</td>\n",
       "      <td>0.4662</td>\n",
       "      <td>522</td>\n",
       "      <td>426</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Wes Unseld Jr</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.2</td>\n",
       "      <td>0.4320</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Wes Unseld Jr</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.4126</td>\n",
       "      <td>70</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Wes Unseld Jr</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>37.8</td>\n",
       "      <td>0.3680</td>\n",
       "      <td>72</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>570 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Team ID   Season Team          Coach Seed  Wins  Losses  Win PCT  \\\n",
       "0    1610612737  2005-06  ATL   Mike Woodson   14    26      56    0.317   \n",
       "1    1610612737  2006-07  ATL   Mike Woodson   13    30      52    0.366   \n",
       "2    1610612737  2007-08  ATL   Mike Woodson    8    37      45    0.451   \n",
       "3    1610612737  2008-09  ATL   Mike Woodson    4    47      35    0.573   \n",
       "4    1610612737  2009-10  ATL   Mike Woodson    3    53      29    0.646   \n",
       "..          ...      ...  ...            ...  ...   ...     ...      ...   \n",
       "565  1610612764  2019-20  WAS   Scott Brooks    9    25      47    0.347   \n",
       "566  1610612764  2020-21  WAS   Scott Brooks    8    34      38    0.472   \n",
       "567  1610612764  2021-22  WAS  Wes Unseld Jr   12    35      47    0.427   \n",
       "568  1610612764  2022-23  WAS  Wes Unseld Jr   12    35      47    0.427   \n",
       "569  1610612764  2023-24  WAS  Wes Unseld Jr   14     2      10    0.167   \n",
       "\n",
       "     Clinched Playoffs  Clinched Conference  ...  Avg Losses T-5 Seasons  \\\n",
       "0                    0                    0  ...                     NaN   \n",
       "1                    1                    0  ...                     NaN   \n",
       "2                    1                    0  ...                     NaN   \n",
       "3                    1                    0  ...                     NaN   \n",
       "4                    1                    0  ...                    43.4   \n",
       "..                 ...                  ...  ...                     ...   \n",
       "565                  0                    0  ...                    42.0   \n",
       "566                  1                    0  ...                    41.4   \n",
       "567                  0                    0  ...                    44.2   \n",
       "568                  0                    0  ...                    45.8   \n",
       "569                  0                    0  ...                    37.8   \n",
       "\n",
       "     Avg Win PCT T-5 Seasons  Agg. Coach Wins  Agg. Coach Losses  Helper  \\\n",
       "0                        NaN               26                 56       1   \n",
       "1                        NaN               56                108       1   \n",
       "2                        NaN               93                153       1   \n",
       "3                        NaN              140                188       1   \n",
       "4                     0.4706              193                217       1   \n",
       "..                       ...              ...                ...     ...   \n",
       "565                   0.4718              488                388       1   \n",
       "566                   0.4662              522                426       1   \n",
       "567                   0.4320               35                 47       1   \n",
       "568                   0.4126               70                 94       1   \n",
       "569                   0.3680               72                104       1   \n",
       "\n",
       "     Coach Experience  Agg. Playoffs Coached  Agg. Conference Finals Coached  \\\n",
       "0                   1                      0                               0   \n",
       "1                   2                      1                               0   \n",
       "2                   3                      2                               0   \n",
       "3                   4                      3                               0   \n",
       "4                   5                      4                               0   \n",
       "..                ...                    ...                             ...   \n",
       "565                11                      7                               1   \n",
       "566                12                      8                               1   \n",
       "567                 1                      0                               0   \n",
       "568                 2                      0                               0   \n",
       "569                 3                      0                               0   \n",
       "\n",
       "     Agg. Coach Titles Won  New Coach  \n",
       "0                      0.0       True  \n",
       "1                      0.0      False  \n",
       "2                      0.0      False  \n",
       "3                      0.0      False  \n",
       "4                      0.0      False  \n",
       "..                     ...        ...  \n",
       "565                    0.0      False  \n",
       "566                    0.0      False  \n",
       "567                    0.0       True  \n",
       "568                    0.0      False  \n",
       "569                    0.0      False  \n",
       "\n",
       "[570 rows x 22 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_coachagg['New Coach'] = combined_df_coachagg.groupby('Team')['Coach'].transform(lambda x: x.ne(x.shift()))\n",
    "combined_df_coachagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Team</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>Win PCT</th>\n",
       "      <th>Clinched Playoffs</th>\n",
       "      <th>Clinched Conference</th>\n",
       "      <th>Won Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2005-06</td>\n",
       "      <td>ATL</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>56</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2006-07</td>\n",
       "      <td>ATL</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>52</td>\n",
       "      <td>0.366</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2007-08</td>\n",
       "      <td>ATL</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "      <td>0.451</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2008-09</td>\n",
       "      <td>ATL</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>35</td>\n",
       "      <td>0.573</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2009-10</td>\n",
       "      <td>ATL</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>29</td>\n",
       "      <td>0.646</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>WAS</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>47</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2020-21</td>\n",
       "      <td>WAS</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td>0.472</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>WAS</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>WAS</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>WAS</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>570 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Team ID   Season Team Seed Wins Losses  Win PCT Clinched Playoffs  \\\n",
       "0    1610612737  2005-06  ATL   14   26     56    0.317                 0   \n",
       "1    1610612737  2006-07  ATL   13   30     52    0.366                 1   \n",
       "2    1610612737  2007-08  ATL    8   37     45    0.451                 1   \n",
       "3    1610612737  2008-09  ATL    4   47     35    0.573                 1   \n",
       "4    1610612737  2009-10  ATL    3   53     29    0.646                 1   \n",
       "..          ...      ...  ...  ...  ...    ...      ...               ...   \n",
       "565  1610612764  2019-20  WAS    9   25     47    0.347                 0   \n",
       "566  1610612764  2020-21  WAS    8   34     38    0.472                 1   \n",
       "567  1610612764  2021-22  WAS   12   35     47    0.427                 0   \n",
       "568  1610612764  2022-23  WAS   12   35     47    0.427                 0   \n",
       "569  1610612764  2023-24  WAS   14    2     10    0.167                 0   \n",
       "\n",
       "    Clinched Conference  Won Title  \n",
       "0                     0        0.0  \n",
       "1                     0        0.0  \n",
       "2                     0        0.0  \n",
       "3                     0        0.0  \n",
       "4                     0        0.0  \n",
       "..                  ...        ...  \n",
       "565                   0        0.0  \n",
       "566                   0        0.0  \n",
       "567                   0        0.0  \n",
       "568                   0        0.0  \n",
       "569                   0        NaN  \n",
       "\n",
       "[570 rows x 10 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = combined_df.sort_values(['Team', 'Season'])\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "combined_df = combined_df.drop(columns='Coach')\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.insert(3, 'Coach', combined_df_coachagg['Coach'])\n",
    "combined_df['Agg. Coach Wins'] = combined_df_coachagg['Agg. Coach Wins']\n",
    "combined_df['Agg. Coach Losses'] = combined_df_coachagg['Agg. Coach Losses']\n",
    "combined_df['Coach Experience'] = combined_df_coachagg['Coach Experience']\n",
    "combined_df['Agg. Playoffs Coached'] = combined_df_coachagg['Agg. Playoffs Coached']\n",
    "combined_df['Agg. Conference Finals Coached'] = combined_df_coachagg['Agg. Conference Finals Coached']\n",
    "combined_df['Agg. Coach Titles Won'] = combined_df_coachagg['Agg. Coach Titles Won']\n",
    "combined_df['New Coach'] = combined_df_coachagg['New Coach']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('/Users/kelvin/Documents/projects-learning/repositories/sports-analytics/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed Type Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The seed type classification is based on a straightforward definition:\n",
    "- Assign a seed type of 1 if the team's seed is in the range of 1 to 4.\n",
    "- Assign a seed type of 2 if the team's seed is in the range of 5 to 8.\n",
    "- Assign a seed type of 3 otherwise.\n",
    "\n",
    "This approach is designed to be:\n",
    "- Easily predictable: The classification is determined by clear and simple seed ranges.\n",
    "- Generalizable: The seed type categorization provides a high-level understanding of a team's performance expectations.\n",
    "- Removes unnecessary complexity while retaining practicality and information: Instead of predicting the exact seed, the focus is on predicting the general type of team a coach is likely to lead in the regular season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "\n",
    "    data['Coach'] = LabelEncoder().fit_transform(data['Coach'])\n",
    "    x = data.drop(columns=['Season', 'Seed', 'Team', 'Wins', 'Losses', 'Win PCT', 'Seed Type', 'Clinched Playoffs', 'Clinched Conference', 'Won Title'])\n",
    "    y = data['Seed Type']\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4203988621.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Coach'] = LabelEncoder().fit_transform(data['Coach'])\n"
     ]
    }
   ],
   "source": [
    "clean_data = combined_df.dropna()\n",
    "training_data = clean_data[clean_data['Season'] != '2023-24']\n",
    "\n",
    "x, y = preprocess_data(training_data)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = rf_model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_cs.to_clipboard()\n",
    "#y_train_cs.to_clipboard()\n",
    "#x_test_cs.to_clipboard()\n",
    "#y_test_cs.to_clipboard()\n",
    "\n",
    "x_train_cs.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 46.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4203988621.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Coach'] = LabelEncoder().fit_transform(data['Coach'])\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4203988621.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Coach'] = LabelEncoder().fit_transform(data['Coach'])\n"
     ]
    }
   ],
   "source": [
    "cs_data = clean_data[clean_data['Season'] == '2023-24']\n",
    "x_test_cs, y_test_cs = preprocess_data(cs_data)\n",
    "x_train_cs, y_train_cs = preprocess_data(training_data)\n",
    "\n",
    "rf_cs = RandomForestClassifier(random_state=42)\n",
    "rf_cs.fit(x_train_cs, y_train_cs)\n",
    "\n",
    "y_pred_cs = rf_cs.predict(x_test_cs)\n",
    "accuracy_cs = accuracy_score(y_test_cs, y_pred_cs)\n",
    "print(f\"Accuracy: {accuracy_cs * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 1, 3, 3, 3, 2, 1, 3, 2, 2, 3, 1, 3, 3, 1, 3, 3, 3, 3, 3, 3,\n",
       "       3, 1, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_train_cs.to_clipboard()\n",
    "#y_train_cs.to_clipboard()\n",
    "#x_test_cs.to_clipboard()\n",
    "#y_test_cs.to_clipboard()\n",
    "\n",
    "y_pred_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_season_predictions = cs_data\n",
    "current_season_predictions.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Team</th>\n",
       "      <th>Coach</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Seed Type</th>\n",
       "      <th>Seed Type Prediction (RF)</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>Win PCT</th>\n",
       "      <th>...</th>\n",
       "      <th>Agg. Coach Wins</th>\n",
       "      <th>Agg. Coach Losses</th>\n",
       "      <th>Coach Experience</th>\n",
       "      <th>Agg. Playoffs Coached</th>\n",
       "      <th>Agg. Conference Finals Coached</th>\n",
       "      <th>Agg. Coach Titles Won</th>\n",
       "      <th>New Coach</th>\n",
       "      <th>Avg Wins T-5 Seasons</th>\n",
       "      <th>Avg Losses T-5 Seasons</th>\n",
       "      <th>Avg Win PCT T-5 Seasons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.500</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>30.2</td>\n",
       "      <td>32.8</td>\n",
       "      <td>0.4784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1610612751</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>BKN</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.500</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>35.6</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.5478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1610612738</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>BOS</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.833</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>40.4</td>\n",
       "      <td>23.6</td>\n",
       "      <td>0.6634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>CHA</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.250</td>\n",
       "      <td>...</td>\n",
       "      <td>226</td>\n",
       "      <td>278</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>25.8</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.3830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1610612741</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>CHI</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.357</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>28.8</td>\n",
       "      <td>34.2</td>\n",
       "      <td>0.4350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1610612739</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>CLE</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.500</td>\n",
       "      <td>...</td>\n",
       "      <td>123</td>\n",
       "      <td>125</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>28.4</td>\n",
       "      <td>34.2</td>\n",
       "      <td>0.4514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1610612742</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>DAL</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.692</td>\n",
       "      <td>...</td>\n",
       "      <td>143</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>36.8</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.5890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1610612743</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>DEN</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750</td>\n",
       "      <td>...</td>\n",
       "      <td>376</td>\n",
       "      <td>273</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>40.6</td>\n",
       "      <td>23.6</td>\n",
       "      <td>0.6528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1610612765</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>DET</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.154</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>16.4</td>\n",
       "      <td>46.6</td>\n",
       "      <td>0.2444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1610612744</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>GSW</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.429</td>\n",
       "      <td>...</td>\n",
       "      <td>479</td>\n",
       "      <td>246</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>31.4</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.4770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1610612745</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>HOU</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.600</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>21.8</td>\n",
       "      <td>41.8</td>\n",
       "      <td>0.3918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1610612754</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>IND</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.636</td>\n",
       "      <td>...</td>\n",
       "      <td>698</td>\n",
       "      <td>674</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>29.2</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.4912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1610612746</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>LAC</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.364</td>\n",
       "      <td>...</td>\n",
       "      <td>238</td>\n",
       "      <td>173</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>37.2</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.5494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1610612747</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>LAL</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0.538</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>35.4</td>\n",
       "      <td>28.6</td>\n",
       "      <td>0.5558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1610612763</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>MEM</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.250</td>\n",
       "      <td>...</td>\n",
       "      <td>182</td>\n",
       "      <td>139</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>36.4</td>\n",
       "      <td>27.8</td>\n",
       "      <td>0.5098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1610612748</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>MIA</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.615</td>\n",
       "      <td>...</td>\n",
       "      <td>712</td>\n",
       "      <td>496</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>37.8</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.5914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1610612749</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>MIL</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.692</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>44.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>0.6854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1610612750</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>MIN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750</td>\n",
       "      <td>...</td>\n",
       "      <td>97</td>\n",
       "      <td>79</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>27.8</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.4878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1610612740</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>NOP</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.462</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>29.0</td>\n",
       "      <td>35.2</td>\n",
       "      <td>0.4522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1610612752</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>NYK</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.615</td>\n",
       "      <td>...</td>\n",
       "      <td>502</td>\n",
       "      <td>387</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>30.8</td>\n",
       "      <td>32.2</td>\n",
       "      <td>0.5052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1610612760</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>OKC</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.692</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>154</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>27.8</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0.4780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1610612753</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>ORL</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.583</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>23.4</td>\n",
       "      <td>40.8</td>\n",
       "      <td>0.4020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1610612755</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>PHI</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>41.2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.6602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1610612756</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>PHX</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.500</td>\n",
       "      <td>...</td>\n",
       "      <td>417</td>\n",
       "      <td>377</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>40.0</td>\n",
       "      <td>24.2</td>\n",
       "      <td>0.6006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1610612757</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>POR</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.250</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>28.0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0.4074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1610612758</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>SAC</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.636</td>\n",
       "      <td>...</td>\n",
       "      <td>401</td>\n",
       "      <td>250</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>29.4</td>\n",
       "      <td>34.4</td>\n",
       "      <td>0.4898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1610612759</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>SAS</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.231</td>\n",
       "      <td>...</td>\n",
       "      <td>914</td>\n",
       "      <td>538</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>24.8</td>\n",
       "      <td>39.2</td>\n",
       "      <td>0.3646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1610612761</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>TOR</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.417</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>34.8</td>\n",
       "      <td>29.2</td>\n",
       "      <td>0.5226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1610612762</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>UTA</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.333</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>37.2</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.5430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>WAS</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.167</td>\n",
       "      <td>...</td>\n",
       "      <td>72</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>26.2</td>\n",
       "      <td>37.8</td>\n",
       "      <td>0.3680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Team ID   Season Team  Coach Seed  Seed Type  \\\n",
       "0   1610612737  2023-24  ATL     20   10          3   \n",
       "1   1610612751  2023-24  BKN     11    9          3   \n",
       "2   1610612738  2023-24  BOS     14    1          1   \n",
       "3   1610612766  2023-24  CHA     22   13          3   \n",
       "4   1610612741  2023-24  CHI      1   12          3   \n",
       "5   1610612739  2023-24  CLE     10    8          2   \n",
       "6   1610612742  2023-24  DAL     13    3          1   \n",
       "7   1610612743  2023-24  DEN     16    2          1   \n",
       "8   1610612765  2023-24  DET     18   15          3   \n",
       "9   1610612744  2023-24  GSW     23   10          3   \n",
       "10  1610612745  2023-24  HOU      9    6          2   \n",
       "11  1610612754  2023-24  IND     21    4          1   \n",
       "12  1610612746  2023-24  LAC     26   11          3   \n",
       "13  1610612747  2023-24  LAL      5    7          2   \n",
       "14  1610612763  2023-24  MEM     24   13          3   \n",
       "15  1610612748  2023-24  MIA      6    5          2   \n",
       "16  1610612749  2023-24  MIL      0    3          1   \n",
       "17  1610612750  2023-24  MIN      3    1          1   \n",
       "18  1610612740  2023-24  NOP     29    9          3   \n",
       "19  1610612752  2023-24  NYK     25    6          2   \n",
       "20  1610612760  2023-24  OKC     15    4          1   \n",
       "21  1610612753  2023-24  ORL     12    7          2   \n",
       "22  1610612755  2023-24  PHI     19    2          1   \n",
       "23  1610612756  2023-24  PHX      7    8          2   \n",
       "24  1610612757  2023-24  POR      2   14          3   \n",
       "25  1610612758  2023-24  SAC     17    5          2   \n",
       "26  1610612759  2023-24  SAS      8   15          3   \n",
       "27  1610612761  2023-24  TOR      4   11          3   \n",
       "28  1610612762  2023-24  UTA     28   12          3   \n",
       "29  1610612764  2023-24  WAS     27   14          3   \n",
       "\n",
       "    Seed Type Prediction (RF)  Wins  Losses  Win PCT  ... Agg. Coach Wins  \\\n",
       "0                           3     6       6    0.500  ...              47   \n",
       "1                           2     6       6    0.500  ...              51   \n",
       "2                           1    10       2    0.833  ...              67   \n",
       "3                           3     3       9    0.250  ...             226   \n",
       "4                           3     5       9    0.357  ...             122   \n",
       "5                           3     6       6    0.500  ...             123   \n",
       "6                           2     9       4    0.692  ...             143   \n",
       "7                           1     9       3    0.750  ...             376   \n",
       "8                           3     2      11    0.154  ...               2   \n",
       "9                           2     6       8    0.429  ...             479   \n",
       "10                          2     6       4    0.600  ...              57   \n",
       "11                          3     7       4    0.636  ...             698   \n",
       "12                          1     4       7    0.364  ...             238   \n",
       "13                          3     7       6    0.538  ...              50   \n",
       "14                          3     3       9    0.250  ...             182   \n",
       "15                          1     8       5    0.615  ...             712   \n",
       "16                          3     9       4    0.692  ...               9   \n",
       "17                          3     9       3    0.750  ...              97   \n",
       "18                          3     6       7    0.462  ...              84   \n",
       "19                          3     8       5    0.615  ...             502   \n",
       "20                          3     9       4    0.692  ...              95   \n",
       "21                          3     7       5    0.583  ...              63   \n",
       "22                          3     9       3    0.750  ...               9   \n",
       "23                          1     6       6    0.500  ...             417   \n",
       "24                          3     3       9    0.250  ...              63   \n",
       "25                          3     7       4    0.636  ...             401   \n",
       "26                          3     3      10    0.231  ...             914   \n",
       "27                          3     5       7    0.417  ...               5   \n",
       "28                          3     4       8    0.333  ...              41   \n",
       "29                          3     2      10    0.167  ...              72   \n",
       "\n",
       "   Agg. Coach Losses  Coach Experience  Agg. Playoffs Coached  \\\n",
       "0                 47                 2                      0   \n",
       "1                 43                 2                      1   \n",
       "2                 27                 2                      1   \n",
       "3                278                 7                      2   \n",
       "4                128                 4                      1   \n",
       "5                125                 4                      1   \n",
       "6                116                 4                      2   \n",
       "7                273                 9                      5   \n",
       "8                 11                 1                      0   \n",
       "9                246                10                      7   \n",
       "10                35                 2                      1   \n",
       "11               674                18                     10   \n",
       "12               173                 6                      4   \n",
       "13                45                 2                      0   \n",
       "14               139                 5                      3   \n",
       "15               496                16                     11   \n",
       "16                 4                 1                      0   \n",
       "17                79                 3                      0   \n",
       "18                93                 3                      0   \n",
       "19               387                12                      8   \n",
       "20               154                 4                      0   \n",
       "21               113                 3                      0   \n",
       "22                 3                 1                      0   \n",
       "23               377                11                      6   \n",
       "24               113                 3                      0   \n",
       "25               250                 9                      7   \n",
       "26               538                19                     14   \n",
       "27                 7                 1                      0   \n",
       "28                53                 2                      0   \n",
       "29               104                 3                      0   \n",
       "\n",
       "    Agg. Conference Finals Coached  Agg. Coach Titles Won  New Coach  \\\n",
       "0                                0                    0.0      False   \n",
       "1                                0                    0.0      False   \n",
       "2                                0                    0.0      False   \n",
       "3                                0                    0.0      False   \n",
       "4                                0                    0.0      False   \n",
       "5                                0                    0.0      False   \n",
       "6                                0                    0.0      False   \n",
       "7                                1                    1.0      False   \n",
       "8                                0                    0.0       True   \n",
       "9                                4                    4.0      False   \n",
       "10                               0                    0.0       True   \n",
       "11                               0                    1.0      False   \n",
       "12                               0                    0.0      False   \n",
       "13                               0                    0.0      False   \n",
       "14                               0                    0.0      False   \n",
       "15                               2                    2.0      False   \n",
       "16                               0                    0.0       True   \n",
       "17                               0                    0.0      False   \n",
       "18                               0                    0.0      False   \n",
       "19                               2                    0.0      False   \n",
       "20                               0                    0.0      False   \n",
       "21                               0                    0.0      False   \n",
       "22                               0                    0.0       True   \n",
       "23                               2                    1.0       True   \n",
       "24                               0                    0.0      False   \n",
       "25                               2                    0.0      False   \n",
       "26                               4                    2.0      False   \n",
       "27                               0                    0.0       True   \n",
       "28                               0                    0.0      False   \n",
       "29                               0                    0.0      False   \n",
       "\n",
       "    Avg Wins T-5 Seasons  Avg Losses T-5 Seasons  Avg Win PCT T-5 Seasons  \n",
       "0                   30.2                    32.8                   0.4784  \n",
       "1                   35.6                    28.4                   0.5478  \n",
       "2                   40.4                    23.6                   0.6634  \n",
       "3                   25.8                    36.8                   0.3830  \n",
       "4                   28.8                    34.2                   0.4350  \n",
       "5                   28.4                    34.2                   0.4514  \n",
       "6                   36.8                    28.0                   0.5890  \n",
       "7                   40.6                    23.6                   0.6528  \n",
       "8                   16.4                    46.6                   0.2444  \n",
       "9                   31.4                    31.6                   0.4770  \n",
       "10                  21.8                    41.8                   0.3918  \n",
       "11                  29.2                    34.8                   0.4912  \n",
       "12                  37.2                    26.6                   0.5494  \n",
       "13                  35.4                    28.6                   0.5558  \n",
       "14                  36.4                    27.8                   0.5098  \n",
       "15                  37.8                    26.6                   0.5914  \n",
       "16                  44.0                    20.4                   0.6854  \n",
       "17                  27.8                    34.6                   0.4878  \n",
       "18                  29.0                    35.2                   0.4522  \n",
       "19                  30.8                    32.2                   0.5052  \n",
       "20                  27.8                    36.4                   0.4780  \n",
       "21                  23.4                    40.8                   0.4020  \n",
       "22                  41.2                    23.0                   0.6602  \n",
       "23                  40.0                    24.2                   0.6006  \n",
       "24                  28.0                    36.4                   0.4074  \n",
       "25                  29.4                    34.4                   0.4898  \n",
       "26                  24.8                    39.2                   0.3646  \n",
       "27                  34.8                    29.2                   0.5226  \n",
       "28                  37.2                    26.8                   0.5430  \n",
       "29                  26.2                    37.8                   0.3680  \n",
       "\n",
       "[30 rows x 23 columns]"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#current_season_predictions = current_season_predictions.drop(columns='Seed Type Prediction (RF)')\n",
    "#current_season_predictions.insert(6, 'Seed Type Prediction (RF)', y_pred_cs)\n",
    "current_season_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 00:29:07,017] A new study created in memory with name: no-name-c5067e3f-987d-4214-b0d4-a1098ffc6dce\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:07,252] Trial 0 finished with value: 0.26666666666666666 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.04582093844965465}. Best is trial 0 with value: 0.26666666666666666.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:07,280] Trial 1 finished with value: 0.4666666666666667 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.04820174313606497}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:07,304] Trial 2 finished with value: 0.3333333333333333 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.04667363197163563}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:07,328] Trial 3 finished with value: 0.4666666666666667 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.011254667046985484}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:07,379] Trial 4 finished with value: 0.4666666666666667 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.025686978436608977}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:07,406] Trial 5 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.01519206578986404}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:07,445] Trial 6 finished with value: 0.4 and parameters: {'max_iter': 500, 'learning_rate_init': 0.024345231744496185}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:07,511] Trial 7 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.0072239144434844815}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:07,661] Trial 8 finished with value: 0.23333333333333334 and parameters: {'max_iter': 500, 'learning_rate_init': 0.04700672075365528}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:07,707] Trial 9 finished with value: 0.36666666666666664 and parameters: {'max_iter': 500, 'learning_rate_init': 0.09361072495827345}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:07,781] Trial 10 finished with value: 0.26666666666666666 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.07027685565920042}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:07,813] Trial 11 finished with value: 0.4 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.005105297774273265}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:07,846] Trial 12 finished with value: 0.4666666666666667 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.02819708329314624}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:07,925] Trial 13 finished with value: 0.26666666666666666 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.06448013669991678}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:07,959] Trial 14 finished with value: 0.26666666666666666 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.03557407651321292}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:07,994] Trial 15 finished with value: 0.26666666666666666 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.00239302230056352}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:08,036] Trial 16 finished with value: 0.4666666666666667 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.015374801678435215}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:08,083] Trial 17 finished with value: 0.4666666666666667 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.038185009788141544}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:08,154] Trial 18 finished with value: 0.26666666666666666 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.058769218812670984}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:08,191] Trial 19 finished with value: 0.4666666666666667 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.016063510613004393}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:08,250] Trial 20 finished with value: 0.23333333333333334 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.0758970133857215}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:08,280] Trial 21 finished with value: 0.4666666666666667 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.027542331066555844}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:08,378] Trial 22 finished with value: 0.4 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.036562255271271424}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:08,408] Trial 23 finished with value: 0.4666666666666667 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.019025465352432602}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:08,441] Trial 24 finished with value: 0.4666666666666667 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.05361961937561434}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:08,472] Trial 25 finished with value: 0.4666666666666667 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.02839671540619368}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:08,504] Trial 26 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.009689053682941887}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:08,533] Trial 27 finished with value: 0.36666666666666664 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.022853695893113375}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:08,570] Trial 28 finished with value: 0.23333333333333334 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.0016125293336974808}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:08,602] Trial 29 finished with value: 0.43333333333333335 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.04093175896549785}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:08,631] Trial 30 finished with value: 0.4666666666666667 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.03253402850087698}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:08,662] Trial 31 finished with value: 0.4 and parameters: {'max_iter': 500, 'learning_rate_init': 0.012283244091738805}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:08,710] Trial 32 finished with value: 0.36666666666666664 and parameters: {'max_iter': 500, 'learning_rate_init': 0.017940666723190803}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:08,744] Trial 33 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.010421816442125984}. Best is trial 1 with value: 0.4666666666666667.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:08,784] Trial 34 finished with value: 0.5333333333333333 and parameters: {'max_iter': 500, 'learning_rate_init': 0.02084696282632509}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:08,827] Trial 35 finished with value: 0.5333333333333333 and parameters: {'max_iter': 500, 'learning_rate_init': 0.020964263729452537}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:08,893] Trial 36 finished with value: 0.43333333333333335 and parameters: {'max_iter': 500, 'learning_rate_init': 0.023029333394922715}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:08,929] Trial 37 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.04325113906385067}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:08,966] Trial 38 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.007228295602679522}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:08,996] Trial 39 finished with value: 0.5 and parameters: {'max_iter': 500, 'learning_rate_init': 0.03313702952211441}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,035] Trial 40 finished with value: 0.5 and parameters: {'max_iter': 500, 'learning_rate_init': 0.0334908283198229}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,079] Trial 41 finished with value: 0.5 and parameters: {'max_iter': 500, 'learning_rate_init': 0.0334070769129734}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,111] Trial 42 finished with value: 0.4 and parameters: {'max_iter': 500, 'learning_rate_init': 0.03047119879904569}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,142] Trial 43 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.03367969600790586}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,169] Trial 44 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.021015375120993388}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,208] Trial 45 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.025696993841776476}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,247] Trial 46 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.039347305264705104}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,275] Trial 47 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.031813469206316426}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,302] Trial 48 finished with value: 0.43333333333333335 and parameters: {'max_iter': 500, 'learning_rate_init': 0.044160237250475944}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,330] Trial 49 finished with value: 0.5 and parameters: {'max_iter': 500, 'learning_rate_init': 0.020712040559589705}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,362] Trial 50 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.025610968760644344}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,390] Trial 51 finished with value: 0.5 and parameters: {'max_iter': 500, 'learning_rate_init': 0.02005956155444646}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,423] Trial 52 finished with value: 0.36666666666666664 and parameters: {'max_iter': 500, 'learning_rate_init': 0.029186833467225667}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,487] Trial 53 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.03510280281079333}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,518] Trial 54 finished with value: 0.43333333333333335 and parameters: {'max_iter': 500, 'learning_rate_init': 0.01363771709405752}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,549] Trial 55 finished with value: 0.36666666666666664 and parameters: {'max_iter': 500, 'learning_rate_init': 0.02286202066899259}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,578] Trial 56 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.03117074979866778}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,614] Trial 57 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.016858690517055304}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,642] Trial 58 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.03692747293925123}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,674] Trial 59 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.025953568163655006}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,704] Trial 60 finished with value: 0.5 and parameters: {'max_iter': 500, 'learning_rate_init': 0.019447791487725376}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,738] Trial 61 finished with value: 0.5 and parameters: {'max_iter': 500, 'learning_rate_init': 0.02079121094963219}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,774] Trial 62 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.014692548165207306}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,805] Trial 63 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.026795714936833272}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,838] Trial 64 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.018925858879223795}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,865] Trial 65 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.03360466993399639}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,898] Trial 66 finished with value: 0.36666666666666664 and parameters: {'max_iter': 500, 'learning_rate_init': 0.02920881948315213}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,927] Trial 67 finished with value: 0.4 and parameters: {'max_iter': 500, 'learning_rate_init': 0.021696126511584875}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:09,964] Trial 68 finished with value: 0.4 and parameters: {'max_iter': 500, 'learning_rate_init': 0.0240620168649635}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:10,000] Trial 69 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.015928463521909176}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:10,059] Trial 70 finished with value: 0.26666666666666666 and parameters: {'max_iter': 500, 'learning_rate_init': 0.04785361654429153}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:10,090] Trial 71 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.018561999398912045}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:10,122] Trial 72 finished with value: 0.43333333333333335 and parameters: {'max_iter': 500, 'learning_rate_init': 0.01348669428568558}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:10,158] Trial 73 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.01897398194910236}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:10,199] Trial 74 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.010413107359050657}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:10,236] Trial 75 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.027626456294746957}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:10,267] Trial 76 finished with value: 0.4 and parameters: {'max_iter': 500, 'learning_rate_init': 0.023942338102909456}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:10,294] Trial 77 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.03960612909352829}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:10,335] Trial 78 finished with value: 0.5 and parameters: {'max_iter': 500, 'learning_rate_init': 0.020539615634281052}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:10,364] Trial 79 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.03482894801609346}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:10,394] Trial 80 finished with value: 0.4 and parameters: {'max_iter': 500, 'learning_rate_init': 0.030445722459989742}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:10,420] Trial 81 finished with value: 0.4 and parameters: {'max_iter': 500, 'learning_rate_init': 0.022245383739701512}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:10,448] Trial 82 finished with value: 0.5 and parameters: {'max_iter': 500, 'learning_rate_init': 0.02049172447828915}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:10,481] Trial 83 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.01579507620674817}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:10,515] Trial 84 finished with value: 0.5 and parameters: {'max_iter': 500, 'learning_rate_init': 0.024703835894252207}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:10,543] Trial 85 finished with value: 0.4 and parameters: {'max_iter': 500, 'learning_rate_init': 0.008515701792716227}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:10,571] Trial 86 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.011273387976260546}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:10,607] Trial 87 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.027896881568160975}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:10,769] Trial 88 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.032424571334156556}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:10,800] Trial 89 finished with value: 0.4 and parameters: {'max_iter': 500, 'learning_rate_init': 0.012783038019777152}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:10,829] Trial 90 finished with value: 0.43333333333333335 and parameters: {'max_iter': 500, 'learning_rate_init': 0.0051778714413942065}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:10,858] Trial 91 finished with value: 0.5333333333333333 and parameters: {'max_iter': 500, 'learning_rate_init': 0.020998429641796375}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:10,903] Trial 92 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.01646985680337333}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:10,931] Trial 93 finished with value: 0.5 and parameters: {'max_iter': 500, 'learning_rate_init': 0.020733493676072884}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:10,968] Trial 94 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.02607794466115943}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:11,003] Trial 95 finished with value: 0.4666666666666667 and parameters: {'max_iter': 500, 'learning_rate_init': 0.017524188138051837}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:11,042] Trial 96 finished with value: 0.4 and parameters: {'max_iter': 500, 'learning_rate_init': 0.024369831850379615}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:11,091] Trial 97 finished with value: 0.4 and parameters: {'max_iter': 500, 'learning_rate_init': 0.029247200809836667}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:11,140] Trial 98 finished with value: 0.4 and parameters: {'max_iter': 500, 'learning_rate_init': 0.022452899912247266}. Best is trial 34 with value: 0.5333333333333333.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 00:29:11,194] Trial 99 finished with value: 0.3333333333333333 and parameters: {'max_iter': 500, 'learning_rate_init': 0.03737726487460705}. Best is trial 34 with value: 0.5333333333333333.\n"
     ]
    }
   ],
   "source": [
    "# using optuna to tune hyperparameters\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train_cs)\n",
    "x_test_scaled = scaler.transform(x_test_cs)\n",
    "\n",
    "def objective(trial):\n",
    "    max_iter = trial.suggest_categorical('max_iter', [500, 1000])\n",
    "    learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
    "\n",
    "    nn_clf = MLPClassifier(max_iter=max_iter, learning_rate_init=learning_rate_init, random_state=42, activation='relu')\n",
    "    nn_clf.fit(x_train_cs, y_train_cs)\n",
    "    accuracy_nn = nn_clf.score(x_test_scaled, y_test_cs)\n",
    "\n",
    "    return accuracy_nn\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 23:08:44,187] A new study created in memory with name: no-name-4f56accc-aa60-42f1-ae72-72d9a741ab47\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:44,396] Trial 0 finished with value: 0.4 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.07714030553737529}. Best is trial 0 with value: 0.4.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:44,518] Trial 1 finished with value: 0.36666666666666664 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.045580615490868}. Best is trial 0 with value: 0.4.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:44,625] Trial 2 finished with value: 0.3 and parameters: {'max_iter': 500, 'learning_rate_init': 0.04607036627957086}. Best is trial 0 with value: 0.4.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:44,666] Trial 3 finished with value: 0.2 and parameters: {'max_iter': 500, 'learning_rate_init': 0.04792662583215521}. Best is trial 0 with value: 0.4.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:44,764] Trial 4 finished with value: 0.2 and parameters: {'max_iter': 500, 'learning_rate_init': 0.06591169579533471}. Best is trial 0 with value: 0.4.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:44,794] Trial 5 finished with value: 0.23333333333333334 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.037202490943594145}. Best is trial 0 with value: 0.4.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:44,859] Trial 6 finished with value: 0.3 and parameters: {'max_iter': 500, 'learning_rate_init': 0.036631518107090956}. Best is trial 0 with value: 0.4.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:44,885] Trial 7 finished with value: 0.36666666666666664 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.017522200983494444}. Best is trial 0 with value: 0.4.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:44,936] Trial 8 finished with value: 0.26666666666666666 and parameters: {'max_iter': 500, 'learning_rate_init': 0.02978636252615457}. Best is trial 0 with value: 0.4.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:45,047] Trial 9 finished with value: 0.23333333333333334 and parameters: {'max_iter': 500, 'learning_rate_init': 0.09957390453664931}. Best is trial 0 with value: 0.4.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:45,162] Trial 10 finished with value: 0.4 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.07162422406514775}. Best is trial 0 with value: 0.4.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:45,218] Trial 11 finished with value: 0.36666666666666664 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.07171579275070819}. Best is trial 0 with value: 0.4.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:45,278] Trial 12 finished with value: 0.36666666666666664 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.07487020067216818}. Best is trial 0 with value: 0.4.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:45,325] Trial 13 finished with value: 0.4 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.08803552416540762}. Best is trial 0 with value: 0.4.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:45,386] Trial 14 finished with value: 0.16666666666666666 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.06146862261991642}. Best is trial 0 with value: 0.4.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:45,428] Trial 15 finished with value: 0.16666666666666666 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.08243412494378598}. Best is trial 0 with value: 0.4.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:45,513] Trial 16 finished with value: 0.2 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.06580000812796423}. Best is trial 0 with value: 0.4.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:45,569] Trial 17 finished with value: 0.16666666666666666 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.002534095446228103}. Best is trial 0 with value: 0.4.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:45,642] Trial 18 finished with value: 0.23333333333333334 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.05648817754082226}. Best is trial 0 with value: 0.4.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:45,683] Trial 19 finished with value: 0.2 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.08008713029275392}. Best is trial 0 with value: 0.4.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:45,742] Trial 20 finished with value: 0.23333333333333334 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.09012433246627843}. Best is trial 0 with value: 0.4.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:45,782] Trial 21 finished with value: 0.2 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.08474865734037645}. Best is trial 0 with value: 0.4.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:45,832] Trial 22 finished with value: 0.16666666666666666 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.09200819247909453}. Best is trial 0 with value: 0.4.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:45,883] Trial 23 finished with value: 0.43333333333333335 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.07333534284897306}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:45,978] Trial 24 finished with value: 0.43333333333333335 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.0738630263423199}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:46,013] Trial 25 finished with value: 0.4 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.07745746738228693}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:46,042] Trial 26 finished with value: 0.2 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.057225630141750895}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:46,092] Trial 27 finished with value: 0.43333333333333335 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.07267669590036498}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:46,155] Trial 28 finished with value: 0.2 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.0654687482318619}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:46,208] Trial 29 finished with value: 0.16666666666666666 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.07924073886019434}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:46,264] Trial 30 finished with value: 0.43333333333333335 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.07219574383955088}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:46,301] Trial 31 finished with value: 0.36666666666666664 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.07113331013057568}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:46,328] Trial 32 finished with value: 0.3 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.05447243155022226}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:46,374] Trial 33 finished with value: 0.36666666666666664 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.07503869673326087}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:46,556] Trial 34 finished with value: 0.16666666666666666 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.06164683341009955}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:46,622] Trial 35 finished with value: 0.16666666666666666 and parameters: {'max_iter': 500, 'learning_rate_init': 0.08297108043090337}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:46,702] Trial 36 finished with value: 0.26666666666666666 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.06727540696026192}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:46,810] Trial 37 finished with value: 0.2 and parameters: {'max_iter': 500, 'learning_rate_init': 0.05070265814448077}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:46,876] Trial 38 finished with value: 0.4 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.07577930849856528}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:46,940] Trial 39 finished with value: 0.43333333333333335 and parameters: {'max_iter': 500, 'learning_rate_init': 0.06861290447656757}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:46,982] Trial 40 finished with value: 0.2 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.08514210190481762}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:47,066] Trial 41 finished with value: 0.43333333333333335 and parameters: {'max_iter': 500, 'learning_rate_init': 0.06895938232352598}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:47,120] Trial 42 finished with value: 0.43333333333333335 and parameters: {'max_iter': 500, 'learning_rate_init': 0.0729592100108537}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:47,188] Trial 43 finished with value: 0.23333333333333334 and parameters: {'max_iter': 500, 'learning_rate_init': 0.06342923202557986}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:47,245] Trial 44 finished with value: 0.4 and parameters: {'max_iter': 500, 'learning_rate_init': 0.06926439026703356}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:47,315] Trial 45 finished with value: 0.2 and parameters: {'max_iter': 500, 'learning_rate_init': 0.06056358597343511}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:47,384] Trial 46 finished with value: 0.16666666666666666 and parameters: {'max_iter': 500, 'learning_rate_init': 0.07928890991852511}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:47,519] Trial 47 finished with value: 0.43333333333333335 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.07315724212410336}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:47,605] Trial 48 finished with value: 0.4 and parameters: {'max_iter': 500, 'learning_rate_init': 0.06755359661158437}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:47,655] Trial 49 finished with value: 0.4 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.07767059061270908}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:47,718] Trial 50 finished with value: 0.2 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.05938793739731543}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:47,778] Trial 51 finished with value: 0.43333333333333335 and parameters: {'max_iter': 500, 'learning_rate_init': 0.06862502185553059}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:47,840] Trial 52 finished with value: 0.4 and parameters: {'max_iter': 500, 'learning_rate_init': 0.07024313775802915}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:47,916] Trial 53 finished with value: 0.36666666666666664 and parameters: {'max_iter': 500, 'learning_rate_init': 0.06379734375410608}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:47,963] Trial 54 finished with value: 0.4 and parameters: {'max_iter': 500, 'learning_rate_init': 0.07432803256227195}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:48,026] Trial 55 finished with value: 0.2 and parameters: {'max_iter': 500, 'learning_rate_init': 0.06572045393390273}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:48,066] Trial 56 finished with value: 0.4 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.07141529125222243}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:48,106] Trial 57 finished with value: 0.2 and parameters: {'max_iter': 500, 'learning_rate_init': 0.0797842130818139}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:48,156] Trial 58 finished with value: 0.16666666666666666 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.08686160523396456}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:48,243] Trial 59 finished with value: 0.2 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.08171422672757447}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:48,309] Trial 60 finished with value: 0.4 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.07596981897569918}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:48,366] Trial 61 finished with value: 0.43333333333333335 and parameters: {'max_iter': 500, 'learning_rate_init': 0.0724012659676668}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:48,425] Trial 62 finished with value: 0.43333333333333335 and parameters: {'max_iter': 500, 'learning_rate_init': 0.06808340720443488}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:48,622] Trial 63 finished with value: 0.3333333333333333 and parameters: {'max_iter': 500, 'learning_rate_init': 0.06368699091567473}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:48,681] Trial 64 finished with value: 0.43333333333333335 and parameters: {'max_iter': 500, 'learning_rate_init': 0.07340087018912148}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:48,725] Trial 65 finished with value: 0.4 and parameters: {'max_iter': 500, 'learning_rate_init': 0.07755990447003928}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:48,764] Trial 66 finished with value: 0.16666666666666666 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.08297509762633366}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:48,821] Trial 67 finished with value: 0.4 and parameters: {'max_iter': 500, 'learning_rate_init': 0.07157592030644212}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:48,889] Trial 68 finished with value: 0.2 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.06604496817990474}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:48,918] Trial 69 finished with value: 0.23333333333333334 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.058380994806364946}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:48,982] Trial 70 finished with value: 0.16666666666666666 and parameters: {'max_iter': 500, 'learning_rate_init': 0.0620098707000363}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:49,038] Trial 71 finished with value: 0.4 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.0741395807134752}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:49,103] Trial 72 finished with value: 0.36666666666666664 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.06951636037866661}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:49,144] Trial 73 finished with value: 0.4 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.07674048889818902}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:49,185] Trial 74 finished with value: 0.16666666666666666 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.08114744947333637}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:49,232] Trial 75 finished with value: 0.43333333333333335 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.07331660399506443}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:49,260] Trial 76 finished with value: 0.3 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.0545285903396792}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:49,326] Trial 77 finished with value: 0.4 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.07043133728415392}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:49,387] Trial 78 finished with value: 0.2 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.0784476098427849}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:49,447] Trial 79 finished with value: 0.2 and parameters: {'max_iter': 500, 'learning_rate_init': 0.06596266692682244}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:49,486] Trial 80 finished with value: 0.4 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.07631677937545706}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:49,571] Trial 81 finished with value: 0.4 and parameters: {'max_iter': 500, 'learning_rate_init': 0.06929604675794972}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:49,632] Trial 82 finished with value: 0.4 and parameters: {'max_iter': 500, 'learning_rate_init': 0.06879343175195377}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:49,687] Trial 83 finished with value: 0.43333333333333335 and parameters: {'max_iter': 500, 'learning_rate_init': 0.07383844801660235}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:49,749] Trial 84 finished with value: 0.3333333333333333 and parameters: {'max_iter': 500, 'learning_rate_init': 0.06406064532421755}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:49,786] Trial 85 finished with value: 0.36666666666666664 and parameters: {'max_iter': 500, 'learning_rate_init': 0.07118267078543827}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:49,855] Trial 86 finished with value: 0.4 and parameters: {'max_iter': 500, 'learning_rate_init': 0.06753823455874257}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:49,905] Trial 87 finished with value: 0.2 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.08035998908064376}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:49,964] Trial 88 finished with value: 0.36666666666666664 and parameters: {'max_iter': 500, 'learning_rate_init': 0.07501800305447841}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:50,034] Trial 89 finished with value: 0.16666666666666666 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.06177174630149922}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:50,102] Trial 90 finished with value: 0.36666666666666664 and parameters: {'max_iter': 500, 'learning_rate_init': 0.0719308048308578}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:50,170] Trial 91 finished with value: 0.43333333333333335 and parameters: {'max_iter': 500, 'learning_rate_init': 0.07268044419683238}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:50,254] Trial 92 finished with value: 0.36666666666666664 and parameters: {'max_iter': 500, 'learning_rate_init': 0.06793094931104343}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:50,299] Trial 93 finished with value: 0.4 and parameters: {'max_iter': 500, 'learning_rate_init': 0.07794061785551021}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:50,367] Trial 94 finished with value: 0.26666666666666666 and parameters: {'max_iter': 500, 'learning_rate_init': 0.06507584696452781}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:50,449] Trial 95 finished with value: 0.36666666666666664 and parameters: {'max_iter': 500, 'learning_rate_init': 0.07556884380181576}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:50,515] Trial 96 finished with value: 0.4 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.0703095725950209}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:50,591] Trial 97 finished with value: 0.4 and parameters: {'max_iter': 500, 'learning_rate_init': 0.07321439405121209}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:50,651] Trial 98 finished with value: 0.3 and parameters: {'max_iter': 1000, 'learning_rate_init': 0.06715686222704945}. Best is trial 23 with value: 0.43333333333333335.\n",
      "/var/folders/3z/8j8g_lgs5j7b31l1sp39n6380000gn/T/ipykernel_98654/4255065623.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
      "/Users/kelvin/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "[I 2023-11-20 23:08:50,696] Trial 99 finished with value: 0.16666666666666666 and parameters: {'max_iter': 500, 'learning_rate_init': 0.08337268297757998}. Best is trial 23 with value: 0.43333333333333335.\n"
     ]
    }
   ],
   "source": [
    "# using optuna to tune hyperparameters\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train_cs)\n",
    "x_test_scaled = scaler.transform(x_test_cs)\n",
    "\n",
    "def objective(trial):\n",
    "    max_iter = trial.suggest_categorical('max_iter', [500, 1000])\n",
    "    learning_rate_init = trial.suggest_uniform('learning_rate_init', 0.001, 0.1)\n",
    "\n",
    "    nn_clf = MLPClassifier(max_iter=max_iter, learning_rate_init=learning_rate_init, random_state=42, activation='relu')\n",
    "    nn_clf.fit(x_train_cs, y_train_cs)\n",
    "    accuracy_nn = nn_clf.score(x_test_scaled, y_test_cs)\n",
    "\n",
    "    return accuracy_nn\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train_cs)\n",
    "x_test_scaled = scaler.transform(x_test_cs)\n",
    "\n",
    "nn_model = MLPClassifier(hidden_layer_sizes=(100, ), learning_rate_init=best_params['learning_rate_init'], max_iter=best_params['max_iter'], activation='relu', random_state=42)\n",
    "nn_model.fit(x_train_scaled, y_train_cs)\n",
    "y_pred_nn = nn_model.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0\n",
       "0   2\n",
       "1   2\n",
       "2   2\n",
       "3   3\n",
       "4   3\n",
       "5   2\n",
       "6   2\n",
       "7   1\n",
       "8   3\n",
       "9   1\n",
       "10  2\n",
       "11  2\n",
       "12  2\n",
       "13  3\n",
       "14  3\n",
       "15  1\n",
       "16  1\n",
       "17  3\n",
       "18  3\n",
       "19  1\n",
       "20  3\n",
       "21  3\n",
       "22  2\n",
       "23  1\n",
       "24  3\n",
       "25  1\n",
       "26  3\n",
       "27  3\n",
       "28  3\n",
       "29  3"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_nn = accuracy_score(y_test_cs, y_pred_nn)\n",
    "pred_nn = pd.DataFrame(y_pred_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Team</th>\n",
       "      <th>Coach</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Seed Type</th>\n",
       "      <th>Seed Type Prediction (RF)</th>\n",
       "      <th>Seed Type Prediction (NN)</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Losses</th>\n",
       "      <th>...</th>\n",
       "      <th>Agg. Coach Wins</th>\n",
       "      <th>Agg. Coach Losses</th>\n",
       "      <th>Coach Experience</th>\n",
       "      <th>Agg. Playoffs Coached</th>\n",
       "      <th>Agg. Conference Finals Coached</th>\n",
       "      <th>Agg. Coach Titles Won</th>\n",
       "      <th>New Coach</th>\n",
       "      <th>Avg Wins T-5 Seasons</th>\n",
       "      <th>Avg Losses T-5 Seasons</th>\n",
       "      <th>Avg Win PCT T-5 Seasons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>30.2</td>\n",
       "      <td>32.8</td>\n",
       "      <td>0.4784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1610612751</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>BKN</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>35.6</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.5478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1610612738</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>BOS</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>40.4</td>\n",
       "      <td>23.6</td>\n",
       "      <td>0.6634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1610612766</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>CHA</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>226</td>\n",
       "      <td>278</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>25.8</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.3830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1610612741</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>CHI</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>28.8</td>\n",
       "      <td>34.2</td>\n",
       "      <td>0.4350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1610612739</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>CLE</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>123</td>\n",
       "      <td>125</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>28.4</td>\n",
       "      <td>34.2</td>\n",
       "      <td>0.4514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1610612742</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>DAL</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>143</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>36.8</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.5890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1610612743</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>DEN</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>376</td>\n",
       "      <td>273</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>40.6</td>\n",
       "      <td>23.6</td>\n",
       "      <td>0.6528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1610612765</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>DET</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>16.4</td>\n",
       "      <td>46.6</td>\n",
       "      <td>0.2444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1610612744</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>GSW</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>479</td>\n",
       "      <td>246</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>31.4</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.4770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1610612745</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>HOU</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>21.8</td>\n",
       "      <td>41.8</td>\n",
       "      <td>0.3918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1610612754</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>IND</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>698</td>\n",
       "      <td>674</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>29.2</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.4912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1610612746</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>LAC</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>238</td>\n",
       "      <td>173</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>37.2</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.5494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1610612747</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>LAL</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>35.4</td>\n",
       "      <td>28.6</td>\n",
       "      <td>0.5558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1610612763</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>MEM</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>182</td>\n",
       "      <td>139</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>36.4</td>\n",
       "      <td>27.8</td>\n",
       "      <td>0.5098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1610612748</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>MIA</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>712</td>\n",
       "      <td>496</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>37.8</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.5914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1610612749</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>MIL</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>44.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>0.6854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1610612750</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>MIN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>97</td>\n",
       "      <td>79</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>27.8</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.4878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1610612740</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>NOP</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>29.0</td>\n",
       "      <td>35.2</td>\n",
       "      <td>0.4522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1610612752</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>NYK</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>502</td>\n",
       "      <td>387</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>30.8</td>\n",
       "      <td>32.2</td>\n",
       "      <td>0.5052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1610612760</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>OKC</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>154</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>27.8</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0.4780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1610612753</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>ORL</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>23.4</td>\n",
       "      <td>40.8</td>\n",
       "      <td>0.4020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1610612755</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>PHI</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>41.2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.6602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1610612756</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>PHX</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>417</td>\n",
       "      <td>377</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>40.0</td>\n",
       "      <td>24.2</td>\n",
       "      <td>0.6006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1610612757</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>POR</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>28.0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0.4074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1610612758</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>SAC</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>401</td>\n",
       "      <td>250</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>29.4</td>\n",
       "      <td>34.4</td>\n",
       "      <td>0.4898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1610612759</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>SAS</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>914</td>\n",
       "      <td>538</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>24.8</td>\n",
       "      <td>39.2</td>\n",
       "      <td>0.3646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1610612761</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>TOR</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>34.8</td>\n",
       "      <td>29.2</td>\n",
       "      <td>0.5226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1610612762</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>UTA</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>37.2</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.5430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1610612764</td>\n",
       "      <td>2023-24</td>\n",
       "      <td>WAS</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>72</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>26.2</td>\n",
       "      <td>37.8</td>\n",
       "      <td>0.3680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Team ID   Season Team  Coach Seed  Seed Type  \\\n",
       "0   1610612737  2023-24  ATL     20   10          3   \n",
       "1   1610612751  2023-24  BKN     11    9          3   \n",
       "2   1610612738  2023-24  BOS     14    1          1   \n",
       "3   1610612766  2023-24  CHA     22   13          3   \n",
       "4   1610612741  2023-24  CHI      1   12          3   \n",
       "5   1610612739  2023-24  CLE     10    8          2   \n",
       "6   1610612742  2023-24  DAL     13    3          1   \n",
       "7   1610612743  2023-24  DEN     16    2          1   \n",
       "8   1610612765  2023-24  DET     18   15          3   \n",
       "9   1610612744  2023-24  GSW     23   10          3   \n",
       "10  1610612745  2023-24  HOU      9    6          2   \n",
       "11  1610612754  2023-24  IND     21    4          1   \n",
       "12  1610612746  2023-24  LAC     26   11          3   \n",
       "13  1610612747  2023-24  LAL      5    7          2   \n",
       "14  1610612763  2023-24  MEM     24   13          3   \n",
       "15  1610612748  2023-24  MIA      6    5          2   \n",
       "16  1610612749  2023-24  MIL      0    3          1   \n",
       "17  1610612750  2023-24  MIN      3    1          1   \n",
       "18  1610612740  2023-24  NOP     29    9          3   \n",
       "19  1610612752  2023-24  NYK     25    6          2   \n",
       "20  1610612760  2023-24  OKC     15    4          1   \n",
       "21  1610612753  2023-24  ORL     12    7          2   \n",
       "22  1610612755  2023-24  PHI     19    2          1   \n",
       "23  1610612756  2023-24  PHX      7    8          2   \n",
       "24  1610612757  2023-24  POR      2   14          3   \n",
       "25  1610612758  2023-24  SAC     17    5          2   \n",
       "26  1610612759  2023-24  SAS      8   15          3   \n",
       "27  1610612761  2023-24  TOR      4   11          3   \n",
       "28  1610612762  2023-24  UTA     28   12          3   \n",
       "29  1610612764  2023-24  WAS     27   14          3   \n",
       "\n",
       "    Seed Type Prediction (RF)  Seed Type Prediction (NN)  Wins  Losses  ...  \\\n",
       "0                           3                          2     6       6  ...   \n",
       "1                           2                          2     6       6  ...   \n",
       "2                           1                          2    10       2  ...   \n",
       "3                           3                          3     3       9  ...   \n",
       "4                           3                          3     5       9  ...   \n",
       "5                           3                          2     6       6  ...   \n",
       "6                           2                          2     9       4  ...   \n",
       "7                           1                          1     9       3  ...   \n",
       "8                           3                          3     2      11  ...   \n",
       "9                           2                          1     6       8  ...   \n",
       "10                          2                          2     6       4  ...   \n",
       "11                          3                          2     7       4  ...   \n",
       "12                          1                          2     4       7  ...   \n",
       "13                          3                          3     7       6  ...   \n",
       "14                          3                          3     3       9  ...   \n",
       "15                          1                          1     8       5  ...   \n",
       "16                          3                          1     9       4  ...   \n",
       "17                          3                          3     9       3  ...   \n",
       "18                          3                          3     6       7  ...   \n",
       "19                          3                          1     8       5  ...   \n",
       "20                          3                          3     9       4  ...   \n",
       "21                          3                          3     7       5  ...   \n",
       "22                          3                          2     9       3  ...   \n",
       "23                          1                          1     6       6  ...   \n",
       "24                          3                          3     3       9  ...   \n",
       "25                          3                          1     7       4  ...   \n",
       "26                          3                          3     3      10  ...   \n",
       "27                          3                          3     5       7  ...   \n",
       "28                          3                          3     4       8  ...   \n",
       "29                          3                          3     2      10  ...   \n",
       "\n",
       "    Agg. Coach Wins Agg. Coach Losses Coach Experience  Agg. Playoffs Coached  \\\n",
       "0                47                47                2                      0   \n",
       "1                51                43                2                      1   \n",
       "2                67                27                2                      1   \n",
       "3               226               278                7                      2   \n",
       "4               122               128                4                      1   \n",
       "5               123               125                4                      1   \n",
       "6               143               116                4                      2   \n",
       "7               376               273                9                      5   \n",
       "8                 2                11                1                      0   \n",
       "9               479               246               10                      7   \n",
       "10               57                35                2                      1   \n",
       "11              698               674               18                     10   \n",
       "12              238               173                6                      4   \n",
       "13               50                45                2                      0   \n",
       "14              182               139                5                      3   \n",
       "15              712               496               16                     11   \n",
       "16                9                 4                1                      0   \n",
       "17               97                79                3                      0   \n",
       "18               84                93                3                      0   \n",
       "19              502               387               12                      8   \n",
       "20               95               154                4                      0   \n",
       "21               63               113                3                      0   \n",
       "22                9                 3                1                      0   \n",
       "23              417               377               11                      6   \n",
       "24               63               113                3                      0   \n",
       "25              401               250                9                      7   \n",
       "26              914               538               19                     14   \n",
       "27                5                 7                1                      0   \n",
       "28               41                53                2                      0   \n",
       "29               72               104                3                      0   \n",
       "\n",
       "    Agg. Conference Finals Coached  Agg. Coach Titles Won  New Coach  \\\n",
       "0                                0                    0.0      False   \n",
       "1                                0                    0.0      False   \n",
       "2                                0                    0.0      False   \n",
       "3                                0                    0.0      False   \n",
       "4                                0                    0.0      False   \n",
       "5                                0                    0.0      False   \n",
       "6                                0                    0.0      False   \n",
       "7                                1                    1.0      False   \n",
       "8                                0                    0.0       True   \n",
       "9                                4                    4.0      False   \n",
       "10                               0                    0.0       True   \n",
       "11                               0                    1.0      False   \n",
       "12                               0                    0.0      False   \n",
       "13                               0                    0.0      False   \n",
       "14                               0                    0.0      False   \n",
       "15                               2                    2.0      False   \n",
       "16                               0                    0.0       True   \n",
       "17                               0                    0.0      False   \n",
       "18                               0                    0.0      False   \n",
       "19                               2                    0.0      False   \n",
       "20                               0                    0.0      False   \n",
       "21                               0                    0.0      False   \n",
       "22                               0                    0.0       True   \n",
       "23                               2                    1.0       True   \n",
       "24                               0                    0.0      False   \n",
       "25                               2                    0.0      False   \n",
       "26                               4                    2.0      False   \n",
       "27                               0                    0.0       True   \n",
       "28                               0                    0.0      False   \n",
       "29                               0                    0.0      False   \n",
       "\n",
       "    Avg Wins T-5 Seasons  Avg Losses T-5 Seasons  Avg Win PCT T-5 Seasons  \n",
       "0                   30.2                    32.8                   0.4784  \n",
       "1                   35.6                    28.4                   0.5478  \n",
       "2                   40.4                    23.6                   0.6634  \n",
       "3                   25.8                    36.8                   0.3830  \n",
       "4                   28.8                    34.2                   0.4350  \n",
       "5                   28.4                    34.2                   0.4514  \n",
       "6                   36.8                    28.0                   0.5890  \n",
       "7                   40.6                    23.6                   0.6528  \n",
       "8                   16.4                    46.6                   0.2444  \n",
       "9                   31.4                    31.6                   0.4770  \n",
       "10                  21.8                    41.8                   0.3918  \n",
       "11                  29.2                    34.8                   0.4912  \n",
       "12                  37.2                    26.6                   0.5494  \n",
       "13                  35.4                    28.6                   0.5558  \n",
       "14                  36.4                    27.8                   0.5098  \n",
       "15                  37.8                    26.6                   0.5914  \n",
       "16                  44.0                    20.4                   0.6854  \n",
       "17                  27.8                    34.6                   0.4878  \n",
       "18                  29.0                    35.2                   0.4522  \n",
       "19                  30.8                    32.2                   0.5052  \n",
       "20                  27.8                    36.4                   0.4780  \n",
       "21                  23.4                    40.8                   0.4020  \n",
       "22                  41.2                    23.0                   0.6602  \n",
       "23                  40.0                    24.2                   0.6006  \n",
       "24                  28.0                    36.4                   0.4074  \n",
       "25                  29.4                    34.4                   0.4898  \n",
       "26                  24.8                    39.2                   0.3646  \n",
       "27                  34.8                    29.2                   0.5226  \n",
       "28                  37.2                    26.8                   0.5430  \n",
       "29                  26.2                    37.8                   0.3680  \n",
       "\n",
       "[30 rows x 24 columns]"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#current_season_predictions = current_season_predictions.drop(columns='Seed Type Prediction (NN)')\n",
    "current_season_predictions.insert(7, 'Seed Type Prediction (NN)', pred_nn)\n",
    "current_season_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_model_loss = nn_model.fit(x_train_scaled, y_train_cs).loss_curve_\n",
    "mse_test = mean_squared_error(y_test_cs, y_pred_nn)\n",
    "\n",
    "# Plot the MSE over training epochs\n",
    "plt.plot(nn_model_loss, label='Training MSE')\n",
    "plt.axhline(y=mse_test, color='r', linestyle='--', label='Test MSE') # Reference point\n",
    "plt.title('MSE vs. Training Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model for Team Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
